{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfc5f1af-38f8-4664-8f7f-37c5916853d1",
   "metadata": {},
   "source": [
    "# Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d514801b-cb8f-49c6-85c5-84a49a687ee2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "# !pip install tensorflow\n",
    "# !pip install  spacy\n",
    "# !pip install tqdm\n",
    "# !pip install plotly\n",
    "!pip install jupyter-black\n",
    "!pip install imblearn\n",
    "!pip install transformers\n",
    "!pip install sentencepiece\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab47875-d7b8-467e-9f9a-824abb3b9105",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b92068b-ba2c-4f7d-b774-e77d9743c4f9",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f3f4560-096a-4342-9371-ccb1bbaef8b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba5fcdd3-4daf-4942-bdec-989e2c169e6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T13:18:10.603279Z",
     "iopub.status.busy": "2023-01-19T13:18:10.603000Z",
     "iopub.status.idle": "2023-01-19T13:18:10.680916Z",
     "shell.execute_reply": "2023-01-19T13:18:10.679948Z",
     "shell.execute_reply.started": "2023-01-19T13:18:10.603255Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
       "                (function() {\n",
       "                    if (window.IPython === undefined) {\n",
       "                        return\n",
       "                    }\n",
       "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
       "                        \"jupyter_black in a non-lab notebook with \" +\n",
       "                        \"`is_lab=True`. Please double check, and if \" +\n",
       "                        \"loading with `%load_ext` please review the README!\"\n",
       "                    console.log(msg)\n",
       "                    alert(msg)\n",
       "                })()\n",
       "                </script>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext jupyter_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7a331634-a658-4862-acd5-cb498ef7064f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-19T00:59:12.143294Z",
     "iopub.status.busy": "2023-01-19T00:59:12.142936Z",
     "iopub.status.idle": "2023-01-19T00:59:12.150224Z",
     "shell.execute_reply": "2023-01-19T00:59:12.149332Z",
     "shell.execute_reply.started": "2023-01-19T00:59:12.143268Z"
    }
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44121573-5f12-45de-9286-3e7c4d79050d",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba141e71-43b6-4129-8477-8d5160f317dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read sequences\n",
    "path=\"./data/\"\n",
    "sequences = list()\n",
    "with open(path+\"sequences.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        sequences.append(line[:-1])\n",
    "\n",
    "# Split data into training and test sets\n",
    "sequences_train = list()\n",
    "sequences_test = list()\n",
    "proteins_test = list()\n",
    "train_target = list()\n",
    "with open(path+\"graph_labels.txt\", \"r\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        t = line.split(\",\")\n",
    "        if len(t[1][:-1]) == 0:\n",
    "            proteins_test.append(t[0])\n",
    "            sequences_test.append(sequences[i])\n",
    "        else:\n",
    "            sequences_train.append(sequences[i])\n",
    "            train_target.append(int(t[1][:-1]))\n",
    "\n",
    "sequences_train = np.array(sequences_train)\n",
    "train_target = np.array(train_target)\n",
    "sequences_test = np.array(sequences_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d37beaf-7bc8-4804-b9e7-c69442ddd119",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"seq\": sequences_train, \"target\": train_target})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e226940-ef41-4472-81cf-aa6197057635",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unseen = pd.DataFrame({\"seq\": sequences_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d50ec40a-3d0e-4cb5-9272-18352a1dd755",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.target.hist(bins=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aacf27f7-e549-4140-8709-8ff3cf6273ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4888, 1223)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(sequences_train),len(sequences_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb09912-9982-4aa5-94f2-d2393c28ab47",
   "metadata": {},
   "source": [
    "- We notice that the data is imbalanced.\n",
    "- we have 18 class\n",
    "- we have 4888 sequences for training set and 1223 for testing set "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c486ada-3494-480a-b89b-10a4ef126657",
   "metadata": {},
   "source": [
    "Let's compute the mean and std of number o caracteres in each sequence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd51e667-f8c5-4945-8da1-fb1460e584ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 258.14 and std is 162.24\n"
     ]
    }
   ],
   "source": [
    "mean_carr = np.mean(data.seq.apply(len))\n",
    "std_carr = np.std(data.seq.apply(len))\n",
    "print(\"mean\", round(mean_carr,2), \"and std is\", round(std_carr,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884f8a40-d81d-4c7a-ab87-6cf914da9fc4",
   "metadata": {},
   "source": [
    "To handle the imbalancing of the target , (we have the majority class 0 is 100 times larger than minority class):\n",
    "- we can oversample minority classes, using multiple good approaches depending on our needs like:\n",
    "- random under sampling : reduce randomly majority classes to be almost close in counts to minority classes\n",
    "- random over sampling : duplicate randomly minority classes to be almost close in counts to majority classes\n",
    "- smote :  creates synthetic samples by selecting two or more nearest neighbors of a minority class instance, and then interpolating the feature values between those instances to create new, synthetic instances.\n",
    "- adasyn : , adapts the synthetic sample generation process based on the density of the minority class. It creates more synthetic samples in the regions where the minority class is denser, and fewer synthetic samples in the regions where the minority class is sparser. This aims to balance the class distribution more effectively.\n",
    "- Using F1 metric:  takes into account the model's ability to correctly identify both the majority and minority classes. If a model has a high F1 score, it means it has a good balance of precision and recall, and is able to correctly identify both the majority and minority classes.\n",
    "\n",
    "- ** class weight **: this is the best approach when it's available, since it interfers directly into the loss function by giving to each class an imporatance score for it's contribution in loss function\n",
    "\n",
    "    ==> we will use in the following the classes weights approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd1968a-5a81-4861-a099-c1346ec96ddc",
   "metadata": {},
   "source": [
    "### Important functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a916f1a-317a-402a-9ec6-db0923a97dd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# numpy softmax function\n",
    "def softmax(x):\n",
    "    y = np.exp(x - np.max(x))\n",
    "    f_x = y / np.sum(np.exp(x))\n",
    "    return f_x\n",
    "\n",
    "\n",
    "softmax_vect = np.vectorize(softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e8af066c-582f-4792-abaa-5f32e32f2ff3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# weighted multi-class log loss\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "\n",
    "def weighted_mc_log_loss(y_true, y_pred, y_pred_proba):\n",
    "    loss = log_loss(y_true, y_pred_proba, labels=np.unique(y_true))\n",
    "    accuracy = (y_true == y_pred).sum() / len(y_true) * 100\n",
    "    return print(f\"loss = {loss:.2f} and accuracy\",f\"{accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "00dc7a6f-c7d5-4cbb-b0a7-539e42eeeb2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# submit function \n",
    "def submit(y_pred_proba,name=''):\n",
    "    # Write predictions to a file\n",
    "    with open(name+\"sample_submission.csv\", \"w\") as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=\",\")\n",
    "        lst = list()\n",
    "        for i in range(18):\n",
    "            lst.append(\"class\" + str(i))\n",
    "        lst.insert(0, \"name\")\n",
    "        writer.writerow(lst)\n",
    "        for i, protein in enumerate(proteins_test):\n",
    "            lst = y_pred_proba[i, :].tolist()\n",
    "            lst.insert(0, protein)\n",
    "            writer.writerow(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ea347c-2cf8-4fe4-aca4-7ae63f266b1b",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a07f7c81-494c-474e-b8ff-97fe4d3fd313",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  s^plit data into train, test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data,  # Features\n",
    "    data.target.to_numpy(),  # Target variable\n",
    "    test_size=0.2,  # 20% test size\n",
    ")\n",
    "X_train = X_train.reset_index(drop=True)  # we reste the indexes\n",
    "X_test = X_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5732cb3c-3238-48bb-891a-30803fcbd11b",
   "metadata": {},
   "source": [
    "## Tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8958e0f6-d707-4651-9ff6-fcda62398cde",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3910, 8465)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map sequences to\n",
    "vec = TfidfVectorizer(analyzer=\"char\", ngram_range=(1, 3))\n",
    "X_train_tf = vec.fit_transform(X_train.seq)\n",
    "X_test_tf = vec.transform(X_test.seq)\n",
    "X_unseen = vec.transform(unseen.seq)\n",
    "X_train_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e37fbf54-f93c-4c26-b9ca-47e6c1bab78d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the weight of each class\n",
    "(unique, counts) = np.unique(y_train, return_counts=True)\n",
    "class_weight = {uni: len(y_train) / count for uni, count in zip(unique, counts)}\n",
    "# class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7b4f7f-1b0e-4197-9906-f81d08d28dea",
   "metadata": {},
   "source": [
    "we use the count of each unique class to weight the classes in the loss function "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8f6d8e-f722-467c-9d8b-cc1545b36d62",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7fe66d7e-5bc2-4219-8bff-b24c30754e46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight={0: 10.831024930747922, 1: 97.75,\n",
       "                                 2: 5.213333333333333, 3: 85.0,\n",
       "                                 4: 44.43181818181818, 5: 7.757936507936508,\n",
       "                                 6: 24.285714285714285, 7: 67.41379310344827,\n",
       "                                 8: 4.936868686868687, 9: 85.0, 10: 122.1875,\n",
       "                                 11: 15.038461538461538, 12: 111.71428571428571,\n",
       "                                 13: 79.79591836734694, 14: 9.178403755868544,\n",
       "                                 15: 21.843575418994412, 16: 78.2,\n",
       "                                 17: 118.48484848484848},\n",
       "                   solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight={0: 10.831024930747922, 1: 97.75,\n",
       "                                 2: 5.213333333333333, 3: 85.0,\n",
       "                                 4: 44.43181818181818, 5: 7.757936507936508,\n",
       "                                 6: 24.285714285714285, 7: 67.41379310344827,\n",
       "                                 8: 4.936868686868687, 9: 85.0, 10: 122.1875,\n",
       "                                 11: 15.038461538461538, 12: 111.71428571428571,\n",
       "                                 13: 79.79591836734694, 14: 9.178403755868544,\n",
       "                                 15: 21.843575418994412, 16: 78.2,\n",
       "                                 17: 118.48484848484848},\n",
       "                   solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(class_weight={0: 10.831024930747922, 1: 97.75,\n",
       "                                 2: 5.213333333333333, 3: 85.0,\n",
       "                                 4: 44.43181818181818, 5: 7.757936507936508,\n",
       "                                 6: 24.285714285714285, 7: 67.41379310344827,\n",
       "                                 8: 4.936868686868687, 9: 85.0, 10: 122.1875,\n",
       "                                 11: 15.038461538461538, 12: 111.71428571428571,\n",
       "                                 13: 79.79591836734694, 14: 9.178403755868544,\n",
       "                                 15: 21.843575418994412, 16: 78.2,\n",
       "                                 17: 118.48484848484848},\n",
       "                   solver='liblinear')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting up the model class\n",
    "lr_model_tf = LogisticRegression(class_weight=class_weight, solver=\"liblinear\")\n",
    "\n",
    "# Training the model\n",
    "lr_model_tf.fit(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "20033c4d-660e-4f29-90fa-c3e719b58fce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.73      0.72        79\n",
      "           1       1.00      0.10      0.18        10\n",
      "           2       0.53      0.71      0.60       189\n",
      "           3       0.89      0.57      0.70        14\n",
      "           4       0.92      0.50      0.65        24\n",
      "           5       0.50      0.68      0.57       121\n",
      "           6       0.75      0.44      0.55        41\n",
      "           7       0.50      0.12      0.20        16\n",
      "           8       0.66      0.71      0.69       206\n",
      "           9       0.33      0.09      0.14        11\n",
      "          10       0.00      0.00      0.00        11\n",
      "          11       0.37      0.56      0.44        45\n",
      "          12       1.00      0.22      0.36         9\n",
      "          13       0.75      0.30      0.43        10\n",
      "          14       0.60      0.49      0.54       122\n",
      "          15       0.65      0.23      0.34        47\n",
      "          16       0.75      0.30      0.43        10\n",
      "          17       1.00      0.31      0.47        13\n",
      "\n",
      "    accuracy                           0.58       978\n",
      "   macro avg       0.66      0.39      0.45       978\n",
      "weighted avg       0.61      0.58      0.57       978\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Calculate key performance metrics\n",
    "test_pred_lr_proba = lr_model_tf.predict_proba(X_test_tf)\n",
    "test_pred_lr = lr_model_tf.predict(X_test_tf)\n",
    "\n",
    "# Print a classification report\n",
    "print(\n",
    "    classification_report(y_test, test_pred_lr)\n",
    ")  # this threshold gives the best weighed average from the ROC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b09f4f92-6f99-4c6e-a825-24bbaff1f24a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 1.79 and accuracy 58.38\n"
     ]
    }
   ],
   "source": [
    "weighted_mc_log_loss(y_test, test_pred_lr, test_pred_lr_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f767d7-a17f-46f5-9c60-e7f03901aa99",
   "metadata": {},
   "source": [
    "### multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c468baa4-dfd1-4d50-a4b8-82520d368e47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.11      0.20        79\n",
      "           1       0.00      0.00      0.00        10\n",
      "           2       0.26      0.96      0.41       189\n",
      "           3       0.00      0.00      0.00        14\n",
      "           4       0.00      0.00      0.00        24\n",
      "           5       1.00      0.08      0.15       121\n",
      "           6       0.00      0.00      0.00        41\n",
      "           7       0.00      0.00      0.00        16\n",
      "           8       0.52      0.68      0.59       206\n",
      "           9       0.00      0.00      0.00        11\n",
      "          10       0.00      0.00      0.00        11\n",
      "          11       0.00      0.00      0.00        45\n",
      "          12       0.00      0.00      0.00         9\n",
      "          13       0.00      0.00      0.00        10\n",
      "          14       1.00      0.01      0.02       122\n",
      "          15       0.00      0.00      0.00        47\n",
      "          16       0.00      0.00      0.00        10\n",
      "          17       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.35       978\n",
      "   macro avg       0.21      0.10      0.08       978\n",
      "weighted avg       0.49      0.35      0.24       978\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_tf, y_train)\n",
    "\n",
    "test_pred_nb_proba = nb.predict_proba(X_test_tf)\n",
    "test_pred_nb = nb.predict(X_test_tf)\n",
    "\n",
    "# Print a classification report\n",
    "print(\n",
    "    classification_report(y_test, test_pred_nb)\n",
    ")  # this threshold gives the best weighed average from the ROC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d082d2bc-31dd-4625-8b44-8a676feaf613",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 3.00 and accuracy 34.97\n"
     ]
    }
   ],
   "source": [
    "weighted_mc_log_loss(y_test, test_pred_nb, test_pred_nb_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ece5fac-4507-48f8-885c-59ed100a8d3b",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f020d84f-185c-4460-ac1e-076ab1a97ace",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CalibratedClassifierCV(base_estimator=LinearSVC(class_weight={0: 10.831024930747922,\n",
       "                                                              1: 97.75,\n",
       "                                                              2: 5.213333333333333,\n",
       "                                                              3: 85.0,\n",
       "                                                              4: 44.43181818181818,\n",
       "                                                              5: 7.757936507936508,\n",
       "                                                              6: 24.285714285714285,\n",
       "                                                              7: 67.41379310344827,\n",
       "                                                              8: 4.936868686868687,\n",
       "                                                              9: 85.0,\n",
       "                                                              10: 122.1875,\n",
       "                                                              11: 15.038461538461538,\n",
       "                                                              12: 111.71428571428571,\n",
       "                                                              13: 79.79591836734694,\n",
       "                                                              14: 9.178403755868544,\n",
       "                                                              15: 21.843575418994412,\n",
       "                                                              16: 78.2,\n",
       "                                                              17: 118.48484848484848}))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CalibratedClassifierCV</label><div class=\"sk-toggleable__content\"><pre>CalibratedClassifierCV(base_estimator=LinearSVC(class_weight={0: 10.831024930747922,\n",
       "                                                              1: 97.75,\n",
       "                                                              2: 5.213333333333333,\n",
       "                                                              3: 85.0,\n",
       "                                                              4: 44.43181818181818,\n",
       "                                                              5: 7.757936507936508,\n",
       "                                                              6: 24.285714285714285,\n",
       "                                                              7: 67.41379310344827,\n",
       "                                                              8: 4.936868686868687,\n",
       "                                                              9: 85.0,\n",
       "                                                              10: 122.1875,\n",
       "                                                              11: 15.038461538461538,\n",
       "                                                              12: 111.71428571428571,\n",
       "                                                              13: 79.79591836734694,\n",
       "                                                              14: 9.178403755868544,\n",
       "                                                              15: 21.843575418994412,\n",
       "                                                              16: 78.2,\n",
       "                                                              17: 118.48484848484848}))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">base_estimator: LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC(class_weight={0: 10.831024930747922, 1: 97.75, 2: 5.213333333333333,\n",
       "                        3: 85.0, 4: 44.43181818181818, 5: 7.757936507936508,\n",
       "                        6: 24.285714285714285, 7: 67.41379310344827,\n",
       "                        8: 4.936868686868687, 9: 85.0, 10: 122.1875,\n",
       "                        11: 15.038461538461538, 12: 111.71428571428571,\n",
       "                        13: 79.79591836734694, 14: 9.178403755868544,\n",
       "                        15: 21.843575418994412, 16: 78.2,\n",
       "                        17: 118.48484848484848})</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC(class_weight={0: 10.831024930747922, 1: 97.75, 2: 5.213333333333333,\n",
       "                        3: 85.0, 4: 44.43181818181818, 5: 7.757936507936508,\n",
       "                        6: 24.285714285714285, 7: 67.41379310344827,\n",
       "                        8: 4.936868686868687, 9: 85.0, 10: 122.1875,\n",
       "                        11: 15.038461538461538, 12: 111.71428571428571,\n",
       "                        13: 79.79591836734694, 14: 9.178403755868544,\n",
       "                        15: 21.843575418994412, 16: 78.2,\n",
       "                        17: 118.48484848484848})</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "CalibratedClassifierCV(base_estimator=LinearSVC(class_weight={0: 10.831024930747922,\n",
       "                                                              1: 97.75,\n",
       "                                                              2: 5.213333333333333,\n",
       "                                                              3: 85.0,\n",
       "                                                              4: 44.43181818181818,\n",
       "                                                              5: 7.757936507936508,\n",
       "                                                              6: 24.285714285714285,\n",
       "                                                              7: 67.41379310344827,\n",
       "                                                              8: 4.936868686868687,\n",
       "                                                              9: 85.0,\n",
       "                                                              10: 122.1875,\n",
       "                                                              11: 15.038461538461538,\n",
       "                                                              12: 111.71428571428571,\n",
       "                                                              13: 79.79591836734694,\n",
       "                                                              14: 9.178403755868544,\n",
       "                                                              15: 21.843575418994412,\n",
       "                                                              16: 78.2,\n",
       "                                                              17: 118.48484848484848}))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "svc_init = LinearSVC(class_weight=class_weight)\n",
    "svc = CalibratedClassifierCV(svc_init)\n",
    "svc.fit(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9e266f96-bc16-43e8-89f3-53835097c8be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.68      0.71        79\n",
      "           1       1.00      0.10      0.18        10\n",
      "           2       0.51      0.75      0.60       189\n",
      "           3       1.00      0.50      0.67        14\n",
      "           4       1.00      0.58      0.74        24\n",
      "           5       0.55      0.64      0.59       121\n",
      "           6       0.87      0.49      0.62        41\n",
      "           7       1.00      0.12      0.22        16\n",
      "           8       0.64      0.80      0.71       206\n",
      "           9       1.00      0.09      0.17        11\n",
      "          10       0.00      0.00      0.00        11\n",
      "          11       0.53      0.53      0.53        45\n",
      "          12       1.00      0.56      0.71         9\n",
      "          13       0.75      0.30      0.43        10\n",
      "          14       0.60      0.50      0.55       122\n",
      "          15       0.65      0.23      0.34        47\n",
      "          16       0.75      0.30      0.43        10\n",
      "          17       1.00      0.38      0.56        13\n",
      "\n",
      "    accuracy                           0.61       978\n",
      "   macro avg       0.75      0.42      0.49       978\n",
      "weighted avg       0.64      0.61      0.59       978\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_pred_svc_proba = svc.predict_proba(X_test_tf)\n",
    "test_pred_svc = svc.predict(X_test_tf)\n",
    "\n",
    "# Print a classification report\n",
    "print(\n",
    "    classification_report(y_test, test_pred_svc)\n",
    ")  # this threshold gives the best weighed average from the ROC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7b369c80-1378-4318-bafb-09945e043068",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 1.40 and accuracy 60.74\n"
     ]
    }
   ],
   "source": [
    "weighted_mc_log_loss(y_test, test_pred_svc, test_pred_svc_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c700be2a-a298-4901-bc1e-796dab0101ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-18T22:33:42.928221Z",
     "iopub.status.busy": "2023-01-18T22:33:42.927511Z",
     "iopub.status.idle": "2023-01-18T22:33:46.378431Z",
     "shell.execute_reply": "2023-01-18T22:33:46.377090Z",
     "shell.execute_reply.started": "2023-01-18T22:33:42.928169Z"
    }
   },
   "outputs": [],
   "source": [
    "submit(svc.predict_proba(X_unseen),\"svc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e462caf9-d34c-4b29-98ff-751a9277324d",
   "metadata": {},
   "source": [
    "## Fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "988d3c54-0299-4781-9567-0043f290e930",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !wget https://github.com/facebookresearch/fastText/archive/v0.9.2.zip\n",
    "# !unzip v0.9.2.zip\n",
    "\n",
    "\n",
    "# # # if zip is already downloaded\n",
    "%cd fastText-0.9.2\n",
    "# for command line tool :\n",
    "!make\n",
    "# for python bindings :\n",
    "!pip install .\n",
    "\n",
    "%cd ..\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "86388a18-3adb-410a-9eb1-69367655c322",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import csv\n",
    "\n",
    "\n",
    "# inverseEncodingFastext is mainly to inverse the encoding of the prediction from __label_X to X\n",
    "def inverseEncodingFastext(text):\n",
    "    return int(re.sub(\"__label__\", \"\", str(text)))  # replace __label__ by nothing\n",
    "\n",
    "\n",
    "inverseEncodingFastext_vet = np.vectorize(inverseEncodingFastext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dfb9a208-d3da-4531-9b8e-212b875a7d0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({2: 792, 5: 792, 6: 792, 13: 792, 8: 792, 7: 792, 14: 792, 15: 792, 16: 792, 11: 792, 0: 792, 3: 792, 9: 792, 17: 792, 4: 792, 1: 792, 12: 792, 10: 792})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "# randomly oversample the data in order to balance it\n",
    "oversample = RandomOverSampler(sampling_strategy={k: max(counts) for k in unique})\n",
    "X_over, y_over = oversample.fit_resample(X_train, y_train)\n",
    "print(Counter(y_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "eda2476a-7ff3-4cd4-87a8-9f8c6afb0426",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define and store fasttext initial data as the library requires\n",
    "def labelFastText(dataframe, target, outputName, predictor=\"seq\"):\n",
    "    df = dataframe.copy()\n",
    "    df[\"target\"] = target.copy()\n",
    "    df[\"fastText\"] = df[\"target\"].progress_apply(lambda x: \"__label__\" + str(x))\n",
    "    df = df.dropna(subset=[predictor, \"target\"])\n",
    "    df = df.reset_index(drop=True)  # reset index\n",
    "    df[predictor] = df[predictor].progress_apply(lambda x: \" \".join(list(x)))\n",
    "    df[[\"fastText\", predictor]].to_csv(\n",
    "        (outputName + \".txt\"),\n",
    "        index=False,\n",
    "        sep=\" \",\n",
    "        header=None,\n",
    "        quoting=csv.QUOTE_NONE,\n",
    "        quotechar=\"\",\n",
    "        escapechar=\" \",\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e43f6bfc-796e-49e1-a50e-328c1cc28f4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47148ff3a4764d54a1cbc6154504648b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14256 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6afb24960cd84e13b0642af755b092e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14256 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "672780ba9739401a8daa7234eb06e9ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/978 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbfbe1a2ad2547b39174ed1da24f503e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/978 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = labelFastText(X_over, y_over, \"train\")\n",
    "test = labelFastText(X_test, y_test, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "80cfa564-0fca-42b4-b233-c2b1b927184a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 3M words\n",
      "Number of words:  22\n",
      "Number of labels: 18\n",
      "Progress: 100.0% words/sec/thread:  430865 lr:  0.000000 avg.loss:  1.216084 ETA:   0h 0m 0s 36.6% words/sec/thread:  428541 lr:  0.063375 avg.loss:  2.064179 ETA:   0h 0m39s\n"
     ]
    }
   ],
   "source": [
    "# we train our model\n",
    "model_fasttext = fasttext.train_supervised(\n",
    "    \"train.txt\",\n",
    "    wordNgrams=6,  # n word grams are two\n",
    "    dim=100,  # dimension of embeeding vector or the hidden layer\n",
    "    epoch=50,\n",
    "    loss=\"softmax\",  #we use hirarchical softmax for fast computation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d437575f-6c67-4a69-8649-ada63af6561e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing results for nature de prob are :(978, 0.4785276073619632, 0.4785276073619632)\n"
     ]
    }
   ],
   "source": [
    "results = model_fasttext.test(\"test.txt\")\n",
    "print(f\"testing results for nature de prob are :{results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "95ef27e8-4dfa-448f-8d10-6818d9a506c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this function output the predicted labels\n",
    "def predict_fasttext(text, model):\n",
    "    prediction = model.predict(str(text))  # get the prediction of the model\n",
    "    # return inverseEncodingFastext(prediction[0][0]) # getting prediction directly with 0.5 threshold\n",
    "    return inverseEncodingFastext(prediction[0][0])\n",
    "\n",
    "# this function predicts probabily for each label\n",
    "def predict_fasttext_proba(text, model):\n",
    "    prediction = model.predict(str(text), k=18)  # get the prediction of the model\n",
    "    arr = np.asarray(prediction[0])\n",
    "    ind = inverseEncodingFastext_vet(arr)\n",
    "    ind = ind.argsort()\n",
    "\n",
    "    return prediction[1][ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "15758b78-fc9b-4762-bbf4-fa0c2e4d1c02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92648ea6a07149289315b3f551e66633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/978 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a55040fa8fa44c329db0db14b35323d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/978 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we make our predictions\n",
    "test_pred_fasttext = test.seq.progress_apply(\n",
    "    lambda sent: predict_fasttext(sent, model_fasttext)\n",
    ").to_numpy()\n",
    "test_pred_fasttext_proba = np.stack(\n",
    "    test.seq.progress_apply(lambda sent: predict_fasttext_proba(sent, model_fasttext))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "43b640fd-136c-46ce-8e2e-11bd08fcee47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(list(test_pred_fasttext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ccb59842-8e1c-4966-a6e4-da494eca7224",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.71      0.56        79\n",
      "           1       0.17      0.10      0.12        10\n",
      "           2       0.53      0.50      0.52       189\n",
      "           3       0.67      0.57      0.62        14\n",
      "           4       0.62      0.54      0.58        24\n",
      "           5       0.55      0.49      0.52       121\n",
      "           6       0.43      0.78      0.56        41\n",
      "           7       0.24      0.38      0.29        16\n",
      "           8       0.70      0.45      0.55       206\n",
      "           9       0.38      0.27      0.32        11\n",
      "          10       0.00      0.00      0.00        11\n",
      "          11       0.30      0.47      0.37        45\n",
      "          12       1.00      0.44      0.62         9\n",
      "          13       0.80      0.40      0.53        10\n",
      "          14       0.43      0.43      0.43       122\n",
      "          15       0.17      0.32      0.23        47\n",
      "          16       0.60      0.30      0.40        10\n",
      "          17       1.00      0.31      0.47        13\n",
      "\n",
      "    accuracy                           0.48       978\n",
      "   macro avg       0.50      0.41      0.43       978\n",
      "weighted avg       0.52      0.48      0.48       978\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    classification_report(y_test, test_pred_fasttext)\n",
    ")  # this threshold gives the best weighed average from the ROC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a4f1b0a8-122d-43eb-96a3-ce6f958a1590",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 1.75 and accuracy 47.85\n"
     ]
    }
   ],
   "source": [
    "weighted_mc_log_loss(\n",
    "    y_test,\n",
    "    test_pred_fasttext,\n",
    "    test_pred_fasttext_proba,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4a2445-e207-49e8-a0c2-faa39fb961a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### fatstext embeeding then lightGbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6b22f69e-d93f-40d0-a5c6-c0e0f285f023",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import fasttext\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "\n",
    "fasttextModel =model_fasttext # fasttext.load_model(\"model_fastext.bin\")  # 17000 item /sec\n",
    "\n",
    "\n",
    "def filterXY(X, y, indexes):\n",
    "    X = X[indexes]\n",
    "    y = y[indexes]\n",
    "    return X, y\n",
    "\n",
    "\n",
    "class Classification:\n",
    "    \"\"\"Home made classification with and pycaret\"\"\"\n",
    "\n",
    "    def __init__(self, X, y, vecW=\"fasttext\"):\n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "        self.vecW_ = vecW\n",
    "        self.classesCountStart_ = Counter(self.y_)\n",
    "\n",
    "        print(\"- \" * 40)\n",
    "        print(f\"Classes are {self.classesCountStart_}\")\n",
    "        print(\"- \" * 40)\n",
    "\n",
    "    def sent2vec_(self, text):\n",
    "        if self.vecW_ == \"fasttext\":\n",
    "            return fasttextModel.get_sentence_vector(text)\n",
    "\n",
    "    def fit(self, verbose=False):\n",
    "        self.Xtok_, self.ytok_ = filterXY(\n",
    "            self.X_, self.y_, self.X_.notna()\n",
    "        )  # filter from nan values\n",
    "        print(\"- \" * 40)\n",
    "        print(\"starting sent2vec ...\")\n",
    "        self.Xtok_ = self.X_.progress_apply(self.sent2vec_)\n",
    "        print(\" sent2vec done :)\")\n",
    "        print(\"- \" * 40)\n",
    "        if verbose:\n",
    "            return self.Xtok_\n",
    "\n",
    "    def transform(self, verbose=False):\n",
    "        print(\"transformation from 1D to nD is done\")\n",
    "        self.Xtransformed_, self.Ytransformed_ = filterXY(\n",
    "            self.Xtok_, self.ytok_, self.Xtok_.notna()\n",
    "        )\n",
    "        self.Xtransformed_ = np.stack(self.Xtransformed_)\n",
    "        print(\"- \" * 40)\n",
    "        if verbose:\n",
    "            return self.Xtransformed_\n",
    "\n",
    "    def fitPca(self, n_components=100, verbose=True, pca=None):\n",
    "        if not pca:\n",
    "            self.pca_ = PCA(n_components=n_components)\n",
    "            self.pca_.fit(self.Xtransformed_)\n",
    "        else:\n",
    "            print(\"old pca taken into consideration\")\n",
    "            self.pca_ = pca\n",
    "        if verbose:\n",
    "            print(\"the total ratio of explained variance is :\")\n",
    "            print(np.sum(self.pca_.explained_variance_ratio_))\n",
    "            print(\"the cummulative sum of explained variance is :\")\n",
    "            print(np.cumsum(self.pca_.explained_variance_ratio_))\n",
    "        print(\"- \" * 40)\n",
    "        return self.pca_\n",
    "\n",
    "    def balance(self, algo=\"adasyn\"):\n",
    "        print(\"Banalancing data is starting  ...\")\n",
    "        if algo == \"adasyn\":\n",
    "            self.Xtransformed_, self.Ytransformed_ = ADASYN(\n",
    "                n_jobs=-1, sampling_strategy={k: max(counts) for k in unique}\n",
    "            ).fit_resample(self.Xtransformed_, self.Ytransformed_)\n",
    "\n",
    "        elif algo == \"smote\":\n",
    "            self.Xtransformed_, self.Ytransformed_ = SMOTE(n_jobs=-1).fit_resample(\n",
    "                self.Xtransformed_, self.Ytransformed_\n",
    "            )\n",
    "\n",
    "        print(\"Banalancing data with \" + algo + \"is Done :)\")\n",
    "\n",
    "    def todataFrame(self, withPca=False):\n",
    "        # raise DeprecationWarning('to use pca you should call the function .fitPca, then assign True to withPca args')\n",
    "        self.df_ = self.Xtransformed_\n",
    "        if withPca and self.pca_:\n",
    "            self.df_ = self.pca_.transform(self.df_)\n",
    "        self.df_ = pd.DataFrame(self.df_)\n",
    "        self.df_[\"label_orig\"] = self.Ytransformed_\n",
    "        print(\"- \" * 40)\n",
    "        print(f\"shape of dataframe is {self.df_.shape}\")\n",
    "        self.classesCountEnd_ = Counter(self.df_[\"label_orig\"])\n",
    "        print(f\"Classes in the end are {self.classesCountEnd_}\")\n",
    "        return self.df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "65619b08-21bb-49f2-9b90-69bca144238b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "Classes are Counter({8: 792, 2: 750, 5: 504, 14: 426, 0: 361, 11: 260, 15: 179, 6: 161, 4: 88, 7: 58, 16: 50, 13: 49, 3: 46, 9: 46, 1: 40, 12: 35, 17: 33, 10: 32})\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "starting sent2vec ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93277c0d31ac4fc698a8c055ce59fd11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " sent2vec done :)\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "transformation from 1D to nD is done\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "Banalancing data is starting  ...\n",
      "Banalancing data with smoteis Done :)\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "shape of dataframe is (14256, 101)\n",
      "Classes in the end are Counter({2: 792, 5: 792, 6: 792, 13: 792, 8: 792, 7: 792, 14: 792, 15: 792, 16: 792, 11: 792, 0: 792, 3: 792, 9: 792, 17: 792, 4: 792, 1: 792, 12: 792, 10: 792})\n"
     ]
    }
   ],
   "source": [
    "clf = Classification(X_train.seq, y_train, vecW=\"fasttext\")\n",
    "clf.fit()\n",
    "clf.transform()\n",
    "clf.balance(algo=\"smote\")\n",
    "# pca = clf.fitPca(\n",
    "#     n_components=30, verbose=True\n",
    "# )  # if you comment this you should comment [ to be commented 1]\n",
    "X_train_embed = clf.todataFrame(\n",
    "    # withPca=True\n",
    ")  # [ to be commented 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f59cdda5-d2be-4e52-83ef-a2c605a5a799",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "Classes are Counter({8: 206, 2: 189, 14: 122, 5: 121, 0: 79, 15: 47, 11: 45, 6: 41, 4: 24, 7: 16, 3: 14, 17: 13, 10: 11, 9: 11, 13: 10, 1: 10, 16: 10, 12: 9})\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "starting sent2vec ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d246419324e4500bbb8fd7c463e7025",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/978 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " sent2vec done :)\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "transformation from 1D to nD is done\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "shape of dataframe is (978, 101)\n",
      "Classes in the end are Counter({8: 206, 2: 189, 14: 122, 5: 121, 0: 79, 15: 47, 11: 45, 6: 41, 4: 24, 7: 16, 3: 14, 17: 13, 10: 11, 9: 11, 13: 10, 1: 10, 16: 10, 12: 9})\n"
     ]
    }
   ],
   "source": [
    "clf_unseen = Classification(X_test.seq, y_test, vecW=\"fasttext\")\n",
    "clf_unseen.fit()\n",
    "clf_unseen.transform()\n",
    "# clf_unseen.fitPca(pca=pca)\n",
    "\n",
    "X_test_embed = clf_unseen.todataFrame(\n",
    "    # withPca=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "23223d62-e1c2-4fd3-a484-4bb344be3293",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get our embeeding \n",
    "y_train_embed = X_train_embed[\"label_orig\"]\n",
    "X_train_embed = X_train_embed[X_train_embed.columns.difference([\"label_orig\"])]\n",
    "y_test_embed = X_test_embed[\"label_orig\"]\n",
    "X_test_embed = X_test_embed[X_test_embed.columns.difference([\"label_orig\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "088cbc29-8dee-4ee2-8b12-7b358dc992ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install catboost\n",
    "# !pip install xgboost\n",
    "# !pip install lightgbm\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea51ad2-68ba-4b92-8794-891c0eb2de9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "catboost = CatBoostClassifier(iterations=1000,\n",
    "                           task_type=\"GPU\",\n",
    "                           devices='0:1',\n",
    "                           loss_function= 'MultiClass',\n",
    "                           class_weights=class_weight)\n",
    "catboost.fit(X_train_embed,\n",
    "      y_train_embed,\n",
    "          use_best_model=True,eval_set=(X_test_embed,pd.to_numeric(y_test_embed)))\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1539fe71-e156-475b-8ec6-e978f12fb7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best iteration is in  0 which is under 1000 iteration that we made, so no overfitting\n"
     ]
    }
   ],
   "source": [
    "print(\"the best iteration is in \",catboost.get_best_iteration(), \"which is under 1000 iteration that we made, so no overfitting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d218a9e8-ba6b-441b-a057-dc7f845f5603",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.09      0.10        79\n",
      "           1       0.00      0.00      0.00        10\n",
      "           2       0.20      0.28      0.23       189\n",
      "           3       0.00      0.00      0.00        14\n",
      "           4       0.00      0.00      0.00        24\n",
      "           5       0.16      0.17      0.16       121\n",
      "           6       0.09      0.05      0.06        41\n",
      "           7       0.00      0.00      0.00        16\n",
      "           8       0.23      0.28      0.25       206\n",
      "           9       0.00      0.00      0.00        11\n",
      "          10       0.01      0.09      0.02        11\n",
      "          11       0.06      0.02      0.03        45\n",
      "          12       0.00      0.00      0.00         9\n",
      "          13       0.00      0.00      0.00        10\n",
      "          14       0.14      0.09      0.11       122\n",
      "          15       0.08      0.02      0.03        47\n",
      "          16       0.00      0.00      0.00        10\n",
      "          17       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.16       978\n",
      "   macro avg       0.06      0.06      0.06       978\n",
      "weighted avg       0.14      0.16      0.15       978\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_pred_lbg_proba = clf_lgb.predict_proba(X_test_embed)\n",
    "test_pred_lbg = clf_lgb.predict(X_test_embed)\n",
    "\n",
    "# Print a classification report\n",
    "print(\n",
    "    classification_report(y_test, test_pred_lbg)\n",
    ")  # this threshold gives the best weighed average from the ROC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "54ed7cb2-dd8f-40f6-91a2-612b2b6df349",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 3.02 and accuracy 15.64\n"
     ]
    }
   ],
   "source": [
    "weighted_mc_log_loss(y_test, test_pred_lbg, test_pred_lbg_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e812c0fc-8d34-4a7b-8242-1b78be129281",
   "metadata": {},
   "source": [
    "As we can see , after taking the embeeding of the data using fasttext (word2vec) then fitting a catboost model. It appears that we get poor performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7342bc8e-511b-4713-8563-1de3cd33112e",
   "metadata": {},
   "source": [
    "**So untill now, the best approach is Tf-Idf followed by a linearSVC which gives almost 1.4 in log loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618e3e95-099f-4a7d-8962-cbf49f20074d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
