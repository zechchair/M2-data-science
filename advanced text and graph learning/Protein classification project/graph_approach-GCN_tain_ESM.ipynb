{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7eb4734a-6a8f-49fd-91c9-4c2e5676213a",
   "metadata": {},
   "source": [
    "# In this notebook we will benifit from the new features embeeding to train GCN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d514801b-cb8f-49c6-85c5-84a49a687ee2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T22:29:33.863158Z",
     "iopub.status.busy": "2023-01-22T22:29:33.862567Z",
     "iopub.status.idle": "2023-01-22T22:29:41.160821Z",
     "shell.execute_reply": "2023-01-22T22:29:41.159945Z",
     "shell.execute_reply.started": "2023-01-22T22:29:33.863086Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "# !pip install tensorflow\n",
    "# !pip install  spacy\n",
    "# !pip install tqdm\n",
    "# !pip install plotly\n",
    "!pip install jupyter-black\n",
    "!pip install imblearn\n",
    "!pip install joblib --upgrade\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab47875-d7b8-467e-9f9a-824abb3b9105",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b92068b-ba2c-4f7d-b774-e77d9743c4f9",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f3f4560-096a-4342-9371-ccb1bbaef8b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T22:52:18.449727Z",
     "iopub.status.busy": "2023-01-22T22:52:18.449148Z",
     "iopub.status.idle": "2023-01-22T22:52:19.247890Z",
     "shell.execute_reply": "2023-01-22T22:52:19.247179Z",
     "shell.execute_reply.started": "2023-01-22T22:52:18.449664Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba5fcdd3-4daf-4942-bdec-989e2c169e6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T22:52:19.249700Z",
     "iopub.status.busy": "2023-01-22T22:52:19.249089Z",
     "iopub.status.idle": "2023-01-22T22:52:19.324571Z",
     "shell.execute_reply": "2023-01-22T22:52:19.324001Z",
     "shell.execute_reply.started": "2023-01-22T22:52:19.249677Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
       "                (function() {\n",
       "                    if (window.IPython === undefined) {\n",
       "                        return\n",
       "                    }\n",
       "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
       "                        \"jupyter_black in a non-lab notebook with \" +\n",
       "                        \"`is_lab=True`. Please double check, and if \" +\n",
       "                        \"loading with `%load_ext` please review the README!\"\n",
       "                    console.log(msg)\n",
       "                    alert(msg)\n",
       "                })()\n",
       "                </script>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext jupyter_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a331634-a658-4862-acd5-cb498ef7064f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T22:52:19.325696Z",
     "iopub.status.busy": "2023-01-22T22:52:19.325513Z",
     "iopub.status.idle": "2023-01-22T22:52:19.331459Z",
     "shell.execute_reply": "2023-01-22T22:52:19.330816Z",
     "shell.execute_reply.started": "2023-01-22T22:52:19.325678Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd1968a-5a81-4861-a099-c1346ec96ddc",
   "metadata": {},
   "source": [
    "### Important functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a916f1a-317a-402a-9ec6-db0923a97dd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T22:52:20.289889Z",
     "iopub.status.busy": "2023-01-22T22:52:20.289350Z",
     "iopub.status.idle": "2023-01-22T22:52:20.296665Z",
     "shell.execute_reply": "2023-01-22T22:52:20.296070Z",
     "shell.execute_reply.started": "2023-01-22T22:52:20.289866Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    y = np.exp(x - np.max(x))\n",
    "    f_x = y / np.sum(np.exp(x))\n",
    "    return f_x\n",
    "\n",
    "\n",
    "softmax_vect = np.vectorize(softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8af066c-582f-4792-abaa-5f32e32f2ff3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T22:52:21.015262Z",
     "iopub.status.busy": "2023-01-22T22:52:21.014706Z",
     "iopub.status.idle": "2023-01-22T22:52:21.024134Z",
     "shell.execute_reply": "2023-01-22T22:52:21.023480Z",
     "shell.execute_reply.started": "2023-01-22T22:52:21.015239Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# weighted multi-class log loss\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "\n",
    "def weighted_mc_log_loss(y_true, y_pred, y_pred_proba):\n",
    "    loss = log_loss(y_true, y_pred_proba, labels=np.unique(y_true))\n",
    "    accuracy = round((y_true == y_pred).sum() / len(y_true) * 100, 2)\n",
    "    return print(f\"{loss = } and accuracy {accuracy = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00dc7a6f-c7d5-4cbb-b0a7-539e42eeeb2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T22:52:21.943633Z",
     "iopub.status.busy": "2023-01-22T22:52:21.943083Z",
     "iopub.status.idle": "2023-01-22T22:52:21.955939Z",
     "shell.execute_reply": "2023-01-22T22:52:21.955316Z",
     "shell.execute_reply.started": "2023-01-22T22:52:21.943611Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def submit(y_pred_proba, name=\"\"):\n",
    "    # Write predictions to a file\n",
    "    with open(\"../Submissions/\" + name + \"Graph_gcn.csv\", \"w\") as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=\",\")\n",
    "        lst = list()\n",
    "        for i in range(18):\n",
    "            lst.append(\"class\" + str(i))\n",
    "        lst.insert(0, \"name\")\n",
    "        writer.writerow(lst)\n",
    "        for i, protein in enumerate(proteins_test):\n",
    "            lst = y_pred_proba[i, :].tolist()\n",
    "            lst.insert(0, protein)\n",
    "            writer.writerow(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d628810-a306-488c-b82b-cf58036532fa",
   "metadata": {},
   "source": [
    "# using structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6be017f7-0fea-45fd-ae55-1f00d2c60aa3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T22:52:25.186282Z",
     "iopub.status.busy": "2023-01-22T22:52:25.185709Z",
     "iopub.status.idle": "2023-01-22T22:52:25.726771Z",
     "shell.execute_reply": "2023-01-22T22:52:25.726098Z",
     "shell.execute_reply.started": "2023-01-22T22:52:25.186258Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Initialize device\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cc2aae1-32bf-4772-8bb2-b001267ecc0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T22:52:26.286804Z",
     "iopub.status.busy": "2023-01-22T22:52:26.286161Z",
     "iopub.status.idle": "2023-01-22T22:52:26.320583Z",
     "shell.execute_reply": "2023-01-22T22:52:26.319909Z",
     "shell.execute_reply.started": "2023-01-22T22:52:26.286779Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "path = \"./data/\"\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    Function that loads graphs\n",
    "    \"\"\"\n",
    "    graph_indicator = np.loadtxt(path + \"graph_indicator.txt\", dtype=np.int64)\n",
    "    _, graph_size = np.unique(graph_indicator, return_counts=True)\n",
    "\n",
    "    edges = np.loadtxt(path + \"edgelist.txt\", dtype=np.int64, delimiter=\",\")\n",
    "    edges_inv = np.vstack((edges[:, 1], edges[:, 0]))\n",
    "    edges = np.vstack((edges, edges_inv.T))\n",
    "    s = edges[:, 0] * graph_indicator.size + edges[:, 1]\n",
    "    idx_sort = np.argsort(s)\n",
    "    edges = edges[idx_sort, :]\n",
    "    edges, idx_unique = np.unique(edges, axis=0, return_index=True)\n",
    "    A = sp.csr_matrix(\n",
    "        (np.ones(edges.shape[0]), (edges[:, 0], edges[:, 1])),\n",
    "        shape=(graph_indicator.size, graph_indicator.size),\n",
    "    )\n",
    "\n",
    "    x = np.loadtxt(path + \"node_attributes.txt\", delimiter=\",\")\n",
    "    edge_attr = np.loadtxt(path + \"edge_attributes.txt\", delimiter=\",\")\n",
    "    edge_attr = np.vstack((edge_attr, edge_attr))\n",
    "    edge_attr = edge_attr[idx_sort, :]\n",
    "    edge_attr = edge_attr[idx_unique, :]\n",
    "\n",
    "    adj = []\n",
    "    features = []\n",
    "    edge_features = []\n",
    "    idx_n = 0\n",
    "    idx_m = 0\n",
    "    for i in range(graph_size.size):\n",
    "        adj.append(A[idx_n : idx_n + graph_size[i], idx_n : idx_n + graph_size[i]])\n",
    "        edge_features.append(edge_attr[idx_m : idx_m + adj[i].nnz, :])\n",
    "        features.append(x[idx_n : idx_n + graph_size[i], :])\n",
    "        idx_n += graph_size[i]\n",
    "        idx_m += adj[i].nnz\n",
    "\n",
    "    return adj, features, edge_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a06e3c3-1719-45bc-b17d-57424bbe290b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T22:52:27.236365Z",
     "iopub.status.busy": "2023-01-22T22:52:27.235773Z",
     "iopub.status.idle": "2023-01-22T22:52:27.252237Z",
     "shell.execute_reply": "2023-01-22T22:52:27.251529Z",
     "shell.execute_reply.started": "2023-01-22T22:52:27.236340Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize_adjacency(A):\n",
    "    \"\"\"\n",
    "    Function that normalizes an adjacency matrix\n",
    "    \"\"\"\n",
    "    n = A.shape[0]\n",
    "    A += sp.identity(n)\n",
    "    degs = A.dot(np.ones(n))\n",
    "    inv_degs = np.power(degs, -1)\n",
    "    D = sp.diags(inv_degs)\n",
    "    A_normalized = D.dot(A)\n",
    "\n",
    "    return A_normalized\n",
    "\n",
    "\n",
    "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
    "    \"\"\"\n",
    "    Function that converts a Scipy sparse matrix to a sparse Torch tensor\n",
    "    \"\"\"\n",
    "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
    "    indices = torch.from_numpy(\n",
    "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64)\n",
    "    )\n",
    "    values = torch.from_numpy(sparse_mx.data)\n",
    "    shape = torch.Size(sparse_mx.shape)\n",
    "    return torch.sparse.FloatTensor(indices, values, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f55ecfc7-9ea9-4a15-83e5-18128cabacee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T22:52:29.082208Z",
     "iopub.status.busy": "2023-01-22T22:52:29.081650Z",
     "iopub.status.idle": "2023-01-22T22:52:53.901388Z",
     "shell.execute_reply": "2023-01-22T22:52:53.900615Z",
     "shell.execute_reply.started": "2023-01-22T22:52:29.082185Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load graphs\n",
    "adj, features, edge_features = load_data()\n",
    "\n",
    "# Normalize adjacency matrices\n",
    "# adj = [normalize_adjacency(A) for A in adj]\n",
    "\n",
    "# Split data into training and test sets\n",
    "adj_train = list()\n",
    "features_train = list()\n",
    "edge_features_train = list()\n",
    "y_train = list()\n",
    "adj_test = list()\n",
    "features_test = list()\n",
    "edge_features_test = list()\n",
    "proteins_test = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f03e358d-2664-4d0f-9450-71e561e6bf4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T22:52:53.903013Z",
     "iopub.status.busy": "2023-01-22T22:52:53.902787Z",
     "iopub.status.idle": "2023-01-22T22:52:53.923658Z",
     "shell.execute_reply": "2023-01-22T22:52:53.923002Z",
     "shell.execute_reply.started": "2023-01-22T22:52:53.902993Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(path + \"graph_labels.txt\", \"r\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        t = line.split(\",\")\n",
    "        if len(t[1][:-1]) == 0:\n",
    "            proteins_test.append(t[0])\n",
    "            adj_test.append(adj[i])\n",
    "            features_test.append(features[i])\n",
    "            edge_features_test.append(edge_features[i])\n",
    "        else:\n",
    "            adj_train.append(adj[i])\n",
    "            features_train.append(features[i])\n",
    "            edge_features_train.append(edge_features[i])\n",
    "            y_train.append(int(t[1][:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b83bb419-6db4-4570-badd-804c1b78aa64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T22:52:53.924868Z",
     "iopub.status.busy": "2023-01-22T22:52:53.924665Z",
     "iopub.status.idle": "2023-01-22T22:52:53.999506Z",
     "shell.execute_reply": "2023-01-22T22:52:53.998811Z",
     "shell.execute_reply.started": "2023-01-22T22:52:53.924849Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6419"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "del edge_features\n",
    "gc.collect(generation=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b379b1a-0af4-475a-86fa-a226514fc21c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T22:52:58.278651Z",
     "iopub.status.busy": "2023-01-22T22:52:58.278369Z",
     "iopub.status.idle": "2023-01-22T22:53:35.453829Z",
     "shell.execute_reply": "2023-01-22T22:53:35.453119Z",
     "shell.execute_reply.started": "2023-01-22T22:52:58.278628Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import joblib as joblib\n",
    "\n",
    "# features_train = joblib.load(\"new_features_3B_params.sav\")\n",
    "features_test = joblib.load(\"new_features_test_3B_params.sav\")\n",
    "n_input = features_train[0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "865db7f2-e812-434c-9a9a-b09cd4768814",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T22:42:11.609504Z",
     "iopub.status.busy": "2023-01-22T22:42:11.608705Z",
     "iopub.status.idle": "2023-01-22T22:42:18.809037Z",
     "shell.execute_reply": "2023-01-22T22:42:18.808283Z",
     "shell.execute_reply.started": "2023-01-22T22:42:11.609478Z"
    }
   },
   "outputs": [],
   "source": [
    "# from torch_geometric.data import Data\n",
    "\n",
    "# for i in range(len(features_train)):\n",
    "#     features_train[i] = Data(\n",
    "#         x=torch.tensor(features_train[i]).float(),\n",
    "#         edge_index=torch.tensor(adj_train[i].todense()).nonzero().t().contiguous(),\n",
    "#         y=y_train[i],\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44ec4553-a9f4-452c-ab8e-86cf96039d0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T22:53:35.455365Z",
     "iopub.status.busy": "2023-01-22T22:53:35.454935Z",
     "iopub.status.idle": "2023-01-22T22:53:37.091178Z",
     "shell.execute_reply": "2023-01-22T22:53:37.090367Z",
     "shell.execute_reply.started": "2023-01-22T22:53:35.455344Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "for i in range(len(features_test)):\n",
    "    features_test[i] = Data(\n",
    "        x=torch.tensor(features_test[i]).float(),\n",
    "        edge_index=torch.tensor(adj_test[i].todense()).nonzero().t().contiguous(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dac71149-8aa1-4fab-b715-bdd27be9ee9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T22:34:16.904878Z",
     "iopub.status.busy": "2023-01-22T22:34:16.904135Z",
     "iopub.status.idle": "2023-01-22T22:34:16.910092Z",
     "shell.execute_reply": "2023-01-22T22:34:16.909513Z",
     "shell.execute_reply.started": "2023-01-22T22:34:16.904854Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[185, 2646], edge_index=[2, 3813], y=8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65625187-f4aa-4a8e-83af-ec2441062d52",
   "metadata": {},
   "source": [
    "we have 726 vector embeedings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28b34880-1507-4f1e-9695-80e14652d2ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T21:07:25.884077Z",
     "iopub.status.busy": "2023-01-22T21:07:25.883417Z",
     "iopub.status.idle": "2023-01-22T21:07:30.477376Z",
     "shell.execute_reply": "2023-01-22T21:07:30.476419Z",
     "shell.execute_reply.started": "2023-01-22T21:07:25.884052Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from torch_geometric.data import Data\n",
    "\n",
    "\n",
    "# def get_Data(adj_train, features_train, edge_features_train, y_train):\n",
    "#     data = []\n",
    "#     for i in range(len(features_train)):\n",
    "#         adj_t = torch.tensor(adj_train[i].todense())\n",
    "#         edge_index = adj_t.nonzero().t().contiguous()\n",
    "#         x = torch.tensor(features_train[i]).float()\n",
    "#         edge_attr = torch.tensor(edge_features_train[i]).float()\n",
    "\n",
    "#         data.append(\n",
    "#             Data(\n",
    "#                 x=x,\n",
    "#                 edge_index=edge_index,\n",
    "#                 # edge_attr=edge_attr,\n",
    "#                 y=y_train[i],\n",
    "#             )\n",
    "#         )\n",
    "#     return data\n",
    "\n",
    "\n",
    "# features_train = get_Data(adj_train, features_train, edge_features_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "794e1c52-cc8a-476b-a838-216df7e94166",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T21:07:30.478892Z",
     "iopub.status.busy": "2023-01-22T21:07:30.478589Z",
     "iopub.status.idle": "2023-01-22T21:07:31.297433Z",
     "shell.execute_reply": "2023-01-22T21:07:31.296731Z",
     "shell.execute_reply.started": "2023-01-22T21:07:30.478873Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def get_Data_pred(adj_train, features_train, edge_features_train):\n",
    "#     data = []\n",
    "#     for i in range(len(features_train)):\n",
    "#         adj_t = torch.tensor(adj_train[i].todense())\n",
    "#         edge_index = adj_t.nonzero().t().contiguous()\n",
    "#         x = torch.tensor(features_train[i]).float()\n",
    "#         edge_attr = torch.tensor(edge_features_train[i]).float()\n",
    "\n",
    "#         data.append(\n",
    "#             Data(\n",
    "#                 x=x,\n",
    "#                 edge_index=edge_index,\n",
    "#                 # edge_attr=edge_attr\n",
    "#             )\n",
    "#         )\n",
    "#     return data\n",
    "\n",
    "\n",
    "# features_test = get_Data_pred(adj_test, features_test, edge_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae53b548-e3e9-4d1a-b8c0-934ac088886a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T22:42:26.695622Z",
     "iopub.status.busy": "2023-01-22T22:42:26.695063Z",
     "iopub.status.idle": "2023-01-22T22:42:26.704047Z",
     "shell.execute_reply": "2023-01-22T22:42:26.703352Z",
     "shell.execute_reply.started": "2023-01-22T22:42:26.695599Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 4399\n",
      "Number of test graphs: 489\n"
     ]
    }
   ],
   "source": [
    "train_dataset = features_train[: int(len(features_train) * 9 / 10)]\n",
    "test_dataset = features_train[int(len(features_train) * 9 / 10) :]\n",
    "\n",
    "print(f\"Number of training graphs: {len(train_dataset)}\")\n",
    "print(f\"Number of test graphs: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ba173eb-176a-4f18-9a29-e33c980ac76b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T22:54:18.789077Z",
     "iopub.status.busy": "2023-01-22T22:54:18.788264Z",
     "iopub.status.idle": "2023-01-22T22:54:18.794992Z",
     "shell.execute_reply": "2023-01-22T22:54:18.794300Z",
     "shell.execute_reply.started": "2023-01-22T22:54:18.789048Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader, NeighborLoader\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
    "pred_loader = DataLoader(features_test, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19dbe0be-36d4-47c3-9295-6c152c445943",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T22:42:30.611019Z",
     "iopub.status.busy": "2023-01-22T22:42:30.610558Z",
     "iopub.status.idle": "2023-01-22T22:42:33.351654Z",
     "shell.execute_reply": "2023-01-22T22:42:33.351027Z",
     "shell.execute_reply.started": "2023-01-22T22:42:30.610994Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1:\n",
      "=======\n",
      "Number of graphs in the current batch: 4\n",
      "DataBatch(x=[1024, 2646], edge_index=[2, 19210], y=[4], batch=[1024], ptr=[5])\n",
      "\n",
      "Step 2:\n",
      "=======\n",
      "Number of graphs in the current batch: 4\n",
      "DataBatch(x=[495, 2646], edge_index=[2, 8561], y=[4], batch=[495], ptr=[5])\n",
      "\n",
      "Step 3:\n",
      "=======\n",
      "Number of graphs in the current batch: 4\n",
      "DataBatch(x=[771, 2646], edge_index=[2, 14257], y=[4], batch=[771], ptr=[5])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show 3 first batches\n",
    "for step, data in enumerate(train_loader):\n",
    "    if step < 3:\n",
    "        print(f\"Step {step + 1}:\")\n",
    "        print(\"=======\")\n",
    "        print(f\"Number of graphs in the current batch: {data.num_graphs}\")\n",
    "        print(data)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf9d7e6-66a9-4808-aef3-35f8d6b2863f",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03dd6a35-7b3e-4a5a-a935-e8862ca4ef08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T22:55:27.923837Z",
     "iopub.status.busy": "2023-01-22T22:55:27.923560Z",
     "iopub.status.idle": "2023-01-22T22:55:28.075016Z",
     "shell.execute_reply": "2023-01-22T22:55:28.074525Z",
     "shell.execute_reply.started": "2023-01-22T22:55:27.923815Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN(\n",
      "  (layer1): GCNConv(2646, 64)\n",
      "  (layer2): GCNConv(64, 32)\n",
      "  (decoder): Linear(in_features=32, out_features=18, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv, GATConv, GINConv, global_add_pool, SAGEConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "num_classes = 18\n",
    "\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name=\"GCN\",\n",
    "        hidden_channels=[64, 64, 32],\n",
    "        num_heads=[1, 1, 1],\n",
    "        dropout=0.02,\n",
    "        n_classes=num_classes,\n",
    "        input_dim=2646,\n",
    "    ):\n",
    "        super(GNN, self).__init__()\n",
    "        self.n_classes = n_classes\n",
    "        self.dropout = dropout\n",
    "        self.hidden_dim = hidden_channels[2]\n",
    "        self.model_name = model_name\n",
    "\n",
    "        if model_name == \"GCN\":\n",
    "            self.layer1 = GCNConv(\n",
    "                in_channels=input_dim, out_channels=hidden_channels[1]\n",
    "            )\n",
    "            self.layer2 = GCNConv(\n",
    "                in_channels=hidden_channels[1], out_channels=hidden_channels[2]\n",
    "            )\n",
    "            # self.layer3 = GCNConv(\n",
    "            #     in_channels=hidden_channels[1], out_channels=hidden_channels[2]\n",
    "            # )\n",
    "\n",
    "        elif model_name == \"GAT\":\n",
    "            self.layer1 = GATConv(\n",
    "                in_channels=input_dim,\n",
    "                out_channels=hidden_channels[0],\n",
    "                heads=num_heads[0],\n",
    "                edge_dim=5,\n",
    "            )\n",
    "            self.layer2 = GATConv(\n",
    "                hidden_channels[0] * num_heads[0],\n",
    "                hidden_channels[1],\n",
    "                heads=num_heads[1],\n",
    "                edge_dim=5,\n",
    "            )\n",
    "            self.layer3 = GATConv(\n",
    "                hidden_channels[1] * num_heads[1],\n",
    "                hidden_channels[2],\n",
    "                heads=1,\n",
    "                edge_dim=5,\n",
    "                concat=False,\n",
    "            )\n",
    "\n",
    "        elif model_name == \"GraphSAGE\":\n",
    "            self.layer1 = SAGEConv(input_dim, hidden_channels[0], aggr=\"lstm\")\n",
    "            self.layer2 = SAGEConv(hidden_channels[0], hidden_channels[1], aggr=\"lstm\")\n",
    "            self.layer3 = SAGEConv(hidden_channels[1], hidden_channels[2], aggr=\"lstm\")\n",
    "\n",
    "        self.decoder = nn.Linear(hidden_channels[2], n_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        if self.model_name == \"GAT\":\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "            x = self.layer1(x, edge_index, edge_attr)\n",
    "            x = F.elu(x)\n",
    "\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "            x = self.layer2(x, edge_index, edge_attr)\n",
    "            x = F.elu(x)\n",
    "\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "            x = self.layer3(x, edge_index, edge_attr)\n",
    "        else:\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "            x = self.layer1(x, edge_index)\n",
    "            x = F.elu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "            x = self.layer2(x, edge_index)\n",
    "\n",
    "        x = F.elu(x)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "        # return F.log_softmax(x, dim=-1)\n",
    "\n",
    "\n",
    "model = GNN().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6212a50-6ae4-4edf-82b4-caa7770e4b13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T22:43:20.840794Z",
     "iopub.status.busy": "2023-01-22T22:43:20.840433Z",
     "iopub.status.idle": "2023-01-22T22:52:01.646970Z",
     "shell.execute_reply": "2023-01-22T22:52:01.645888Z",
     "shell.execute_reply.started": "2023-01-22T22:43:20.840763Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001 loss_train: 2.3409 acc_train: 32.4392 loss_val: 2.1596\n",
      "Validation Loss Decreased(inf--->2.159626) \t Saving The Model\n",
      "\n",
      "\n",
      "Epoch: 002 loss_train: 1.8861 acc_train: 49.8522 loss_val: 1.8533\n",
      "Validation Loss Decreased(2.159626--->1.853253) \t Saving The Model\n",
      "\n",
      "\n",
      "Epoch: 003 loss_train: 1.6268 acc_train: 57.0812 loss_val: 1.6481\n",
      "Validation Loss Decreased(1.853253--->1.648117) \t Saving The Model\n",
      "\n",
      "\n",
      "Epoch: 004 loss_train: 1.4380 acc_train: 61.4912 loss_val: 1.4490\n",
      "Validation Loss Decreased(1.648117--->1.449011) \t Saving The Model\n",
      "\n",
      "\n",
      "Epoch: 005 loss_train: 1.3078 acc_train: 64.2646 loss_val: 1.3626\n",
      "Validation Loss Decreased(1.449011--->1.362644) \t Saving The Model\n",
      "\n",
      "\n",
      "Epoch: 006 loss_train: 1.2094 acc_train: 66.0150 loss_val: 1.2627\n",
      "Validation Loss Decreased(1.362644--->1.262653) \t Saving The Model\n",
      "\n",
      "\n",
      "Epoch: 007 loss_train: 1.1361 acc_train: 68.3337 loss_val: 1.2205\n",
      "Validation Loss Decreased(1.262653--->1.220511) \t Saving The Model\n",
      "\n",
      "\n",
      "Epoch: 008 loss_train: 1.0797 acc_train: 69.4476 loss_val: 1.1862\n",
      "Validation Loss Decreased(1.220511--->1.186200) \t Saving The Model\n",
      "\n",
      "\n",
      "Epoch: 009 loss_train: 1.0347 acc_train: 70.8570 loss_val: 1.1369\n",
      "Validation Loss Decreased(1.186200--->1.136922) \t Saving The Model\n",
      "\n",
      "\n",
      "Epoch: 010 loss_train: 0.9857 acc_train: 71.6981 loss_val: 1.1102\n",
      "Validation Loss Decreased(1.136922--->1.110249) \t Saving The Model\n",
      "\n",
      "\n",
      "Epoch: 011 loss_train: 0.9438 acc_train: 72.9484 loss_val: 1.0545\n",
      "Validation Loss Decreased(1.110249--->1.054493) \t Saving The Model\n",
      "\n",
      "\n",
      "Epoch: 012 loss_train: 0.9147 acc_train: 73.1075 loss_val: 1.0420\n",
      "Validation Loss Decreased(1.054493--->1.041996) \t Saving The Model\n",
      "\n",
      "\n",
      "Epoch: 013 loss_train: 0.8761 acc_train: 74.6988 loss_val: 1.0441\n",
      "Validation loss increased :(\n",
      "Epoch: 014 loss_train: 0.8484 acc_train: 74.9943 loss_val: 1.0534\n",
      "Validation loss increased :(\n",
      "Epoch: 015 loss_train: 0.8191 acc_train: 76.0173 loss_val: 0.9778\n",
      "Validation Loss Decreased(1.041996--->0.977790) \t Saving The Model\n",
      "\n",
      "\n",
      "Epoch: 016 loss_train: 0.7908 acc_train: 76.7447 loss_val: 0.9757\n",
      "Validation Loss Decreased(0.977790--->0.975667) \t Saving The Model\n",
      "\n",
      "\n",
      "Epoch: 017 loss_train: 0.7658 acc_train: 77.5404 loss_val: 0.9561\n",
      "Validation Loss Decreased(0.975667--->0.956051) \t Saving The Model\n",
      "\n",
      "\n",
      "Epoch: 018 loss_train: 0.7380 acc_train: 78.5406 loss_val: 0.9697\n",
      "Validation loss increased :(\n",
      "Epoch: 019 loss_train: 0.7223 acc_train: 78.7224 loss_val: 0.9082\n",
      "Validation Loss Decreased(0.956051--->0.908192) \t Saving The Model\n",
      "\n",
      "\n",
      "Epoch: 020 loss_train: 0.6939 acc_train: 79.4499 loss_val: 0.9016\n",
      "Validation Loss Decreased(0.908192--->0.901617) \t Saving The Model\n",
      "\n",
      "\n",
      "Epoch: 021 loss_train: 0.6748 acc_train: 80.3364 loss_val: 0.8947\n",
      "Validation Loss Decreased(0.901617--->0.894694) \t Saving The Model\n",
      "\n",
      "\n",
      "Epoch: 022 loss_train: 0.6533 acc_train: 80.7911 loss_val: 0.8765\n",
      "Validation Loss Decreased(0.894694--->0.876481) \t Saving The Model\n",
      "\n",
      "\n",
      "Epoch: 023 loss_train: 0.6323 acc_train: 81.7004 loss_val: 0.9445\n",
      "Validation loss increased :(\n",
      "Epoch: 024 loss_train: 0.6171 acc_train: 81.8822 loss_val: 0.8827\n",
      "Validation loss increased :(\n",
      "Epoch: 025 loss_train: 0.5989 acc_train: 82.2005 loss_val: 0.9171\n",
      "Validation loss increased :(\n",
      "Epoch: 026 loss_train: 0.5796 acc_train: 82.4960 loss_val: 0.8759\n",
      "Validation Loss Decreased(0.876481--->0.875919) \t Saving The Model\n",
      "\n",
      "\n",
      "Epoch: 027 loss_train: 0.5592 acc_train: 83.5417 loss_val: 0.9160\n",
      "Validation loss increased :(\n",
      "Epoch: 028 loss_train: 0.5445 acc_train: 84.3828 loss_val: 0.9611\n",
      "Validation loss increased :(\n",
      "Epoch: 029 loss_train: 0.5285 acc_train: 84.5874 loss_val: 0.8763\n",
      "Validation loss increased :(\n",
      "Epoch: 030 loss_train: 0.5103 acc_train: 85.3376 loss_val: 0.8879\n",
      "Validation loss increased :(\n",
      "Epoch: 031 loss_train: 0.4989 acc_train: 86.2014 loss_val: 0.8986\n",
      "Validation loss increased :(\n",
      "Epoch: 032 loss_train: 0.4854 acc_train: 85.8377 loss_val: 0.8378\n",
      "Validation Loss Decreased(0.875919--->0.837839) \t Saving The Model\n",
      "\n",
      "\n",
      "Epoch: 033 loss_train: 0.4665 acc_train: 86.4060 loss_val: 0.8340\n",
      "Validation Loss Decreased(0.837839--->0.834014) \t Saving The Model\n",
      "\n",
      "\n",
      "Epoch: 034 loss_train: 0.4579 acc_train: 86.8834 loss_val: 0.9055\n",
      "Validation loss increased :(\n",
      "Epoch: 035 loss_train: 0.4429 acc_train: 86.9516 loss_val: 0.8843\n",
      "Validation loss increased :(\n",
      "Epoch: 036 loss_train: 0.4270 acc_train: 87.8609 loss_val: 1.0346\n",
      "Validation loss increased :(\n",
      "Epoch: 037 loss_train: 0.4278 acc_train: 88.1564 loss_val: 0.9287\n",
      "Validation loss increased :(\n",
      "Epoch: 038 loss_train: 0.4050 acc_train: 88.1791 loss_val: 0.8887\n",
      "Validation loss increased :(\n",
      "Epoch: 039 loss_train: 0.4009 acc_train: 88.6110 loss_val: 0.9217\n",
      "Validation loss increased :(\n",
      "Epoch: 040 loss_train: 0.3869 acc_train: 88.9748 loss_val: 0.8472\n",
      "Validation loss increased :(\n",
      "Epoch: 041 loss_train: 0.3796 acc_train: 89.4067 loss_val: 0.9047\n",
      "Validation loss increased :(\n",
      "Epoch: 042 loss_train: 0.3653 acc_train: 89.6567 loss_val: 0.9037\n",
      "Validation loss increased :(\n",
      "Epoch: 043 loss_train: 0.3574 acc_train: 90.0659 loss_val: 0.8860\n",
      "Validation loss increased :(\n",
      "Epoch: 044 loss_train: 0.3448 acc_train: 90.2478 loss_val: 0.8912\n",
      "Validation loss increased :(\n",
      "Epoch: 045 loss_train: 0.3377 acc_train: 90.1114 loss_val: 0.8595\n",
      "Validation loss increased :(\n",
      "Epoch: 046 loss_train: 0.3300 acc_train: 90.3842 loss_val: 0.8310\n",
      "Validation Loss Decreased(0.834014--->0.831049) \t Saving The Model\n",
      "\n",
      "\n",
      "Epoch: 047 loss_train: 0.3264 acc_train: 90.5206 loss_val: 0.8801\n",
      "Validation loss increased :(\n",
      "Epoch: 048 loss_train: 0.3134 acc_train: 91.0434 loss_val: 0.8255\n",
      "Validation Loss Decreased(0.831049--->0.825496) \t Saving The Model\n",
      "\n",
      "\n",
      "Epoch: 049 loss_train: 0.3034 acc_train: 91.1798 loss_val: 0.9136\n",
      "Validation loss increased :(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 53>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# test_acc, test_loss = test(test_loader)\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 58\u001b[0m     test_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{:03d}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch),\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss_train: \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(train_loss),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[38;5;66;03m# \"acc_val: {:.4f}\".format(test_acc),\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     )\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;66;03m# print(test(test_loader))\u001b[39;00m\n",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(loader)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\n\u001b[1;32m     37\u001b[0m     loader\n\u001b[1;32m     38\u001b[0m ):  \u001b[38;5;66;03m# Iterate in batches over the training/test dataset.\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 40\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m     pred \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Use the class with highest probability.\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m((pred \u001b[38;5;241m==\u001b[39m data\u001b[38;5;241m.\u001b[39my)\u001b[38;5;241m.\u001b[39msum())  \u001b[38;5;66;03m# Check against ground-truth labels.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36mGNN.forward\u001b[0;34m(self, x, edge_index, edge_attr, batch)\u001b[0m\n\u001b[1;32m     80\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39melu(x)\n\u001b[1;32m     81\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(x, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[0;32m---> 83\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39melu(x)\n\u001b[1;32m     86\u001b[0m x \u001b[38;5;241m=\u001b[39m global_mean_pool(x, batch)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch_geometric/nn/conv/gcn_conv.py:176\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    174\u001b[0m cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_edge_index\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     edge_index, edge_weight \u001b[38;5;241m=\u001b[39m \u001b[43mgcn_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# yapf: disable\u001b[39;49;00m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimproved\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_self_loops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcached:\n\u001b[1;32m    180\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_edge_index \u001b[38;5;241m=\u001b[39m (edge_index, edge_weight)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch_geometric/nn/conv/gcn_conv.py:61\u001b[0m, in \u001b[0;36mgcn_norm\u001b[0;34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, flow, dtype)\u001b[0m\n\u001b[1;32m     57\u001b[0m     edge_weight \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones((edge_index\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m), ), dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m     58\u001b[0m                              device\u001b[38;5;241m=\u001b[39medge_index\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m add_self_loops:\n\u001b[0;32m---> 61\u001b[0m     edge_index, tmp_edge_weight \u001b[38;5;241m=\u001b[39m \u001b[43madd_remaining_self_loops\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_nodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m tmp_edge_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m     edge_weight \u001b[38;5;241m=\u001b[39m tmp_edge_weight\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch_geometric/utils/loop.py:300\u001b[0m, in \u001b[0;36madd_remaining_self_loops\u001b[0;34m(edge_index, edge_attr, fill_value, num_nodes)\u001b[0m\n\u001b[1;32m    297\u001b[0m     inv_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m~\u001b[39mmask\n\u001b[1;32m    298\u001b[0m     loop_attr[edge_index[\u001b[38;5;241m0\u001b[39m][inv_mask]] \u001b[38;5;241m=\u001b[39m edge_attr[inv_mask]\n\u001b[0;32m--> 300\u001b[0m     edge_attr \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([\u001b[43medge_attr\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m, loop_attr], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    302\u001b[0m edge_index \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([edge_index[:, mask], loop_index], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m edge_index, edge_attr\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model = GCN(hidden_channels=64)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001) #weight_decay=1e-4\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "\n",
    "def train():\n",
    "    loss_train = 0\n",
    "    correct = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, data in enumerate(\n",
    "        train_loader\n",
    "    ):  # Iterate in batches over the training dataset.\n",
    "        data.to(device)\n",
    "        out = model(\n",
    "            data.x, data.edge_index, _, data.batch\n",
    "        )  # Perform a single forward pass.\n",
    "        loss = criterion(out, data.y)  # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "        # test part\n",
    "        pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "        correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "        loss_train += criterion(out, data.y)\n",
    "\n",
    "\n",
    "    return correct / len(train_loader.dataset) * 100, loss_train / (i + 1)\n",
    "\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    for i, data in enumerate(\n",
    "        loader\n",
    "    ):  # Iterate in batches over the training/test dataset.\n",
    "        data.to(device)\n",
    "        out = model(data.x, data.edge_index,_, data.batch)\n",
    "        pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "        correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "        loss += criterion(out, data.y)\n",
    "        \n",
    "        \n",
    "    # torch.cuda.empty_cache()\n",
    "    return correct / len(loader.dataset) * 100, loss / (\n",
    "        i + 1\n",
    "    )  # Derive ratio of correct predictions. , proba\n",
    "\n",
    "\n",
    "min_val_loss = float(\"inf\")\n",
    "for epoch in range(1, 401):\n",
    "    train_acc, train_loss = train()\n",
    "    # test_acc, test_loss = test(test_loader)\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        test_loss = test(test_loader)[1].to(\"cpu\").detach().numpy()\n",
    "        print(\n",
    "            \"Epoch: {:03d}\".format(epoch),\n",
    "            \"loss_train: {:.4f}\".format(train_loss),\n",
    "            \"acc_train: {:.4f}\".format(train_acc),\n",
    "            \"loss_val: {:.4f}\".format(test_loss),\n",
    "            # \"acc_val: {:.4f}\".format(test_acc),\n",
    "        )\n",
    "        # print(test(test_loader))\n",
    "        if min_val_loss > test_loss:\n",
    "            print(\n",
    "                f\"Validation Loss Decreased({min_val_loss:.6f}--->{test_loss:.6f}) \\t Saving The Model\"\n",
    "            )\n",
    "            min_val_loss = test_loss\n",
    "            # Saving State Dict\n",
    "            torch.save(model.state_dict(), \"saved_model_150m_pars_GAT.pth\")\n",
    "            print(\"\\n\")\n",
    "        else:\n",
    "            print(\"Validation loss increased :(\")\n",
    "        # print(f\"Epoch: {epoch:03d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "73bf9280-d04e-4ce3-8e3b-f4d4198809b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T22:37:44.180999Z",
     "iopub.status.busy": "2023-01-22T22:37:44.180446Z",
     "iopub.status.idle": "2023-01-22T22:37:44.192669Z",
     "shell.execute_reply": "2023-01-22T22:37:44.191643Z",
     "shell.execute_reply.started": "2023-01-22T22:37:44.180979Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.cuda' has no attribute 'reset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# torch.cuda.empty_cache()\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.cuda' has no attribute 'reset'"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81f7788a-8c94-497c-a68f-8dfd90a8ad0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T22:55:33.473481Z",
     "iopub.status.busy": "2023-01-22T22:55:33.472644Z",
     "iopub.status.idle": "2023-01-22T22:55:33.482276Z",
     "shell.execute_reply": "2023-01-22T22:55:33.481715Z",
     "shell.execute_reply.started": "2023-01-22T22:55:33.473450Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GNN(\n",
       "  (layer1): GCNConv(2646, 64)\n",
       "  (layer2): GCNConv(64, 32)\n",
       "  (decoder): Linear(in_features=32, out_features=18, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"saved_model_150m_params_GAT.pth\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "800be3ae-319f-4e05-9edb-833c85970b41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T22:55:43.277802Z",
     "iopub.status.busy": "2023-01-22T22:55:43.276966Z",
     "iopub.status.idle": "2023-01-22T22:55:43.290017Z",
     "shell.execute_reply": "2023-01-22T22:55:43.289483Z",
     "shell.execute_reply.started": "2023-01-22T22:55:43.277772Z"
    }
   },
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "\n",
    "\n",
    "def predict(loader):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    pred = []\n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        data.to(device)\n",
    "        out = model(data.x, data.edge_index, _, data.batch)\n",
    "        out = softmax(out)\n",
    "        pred.append(out.to(\"cpu\").numpy())\n",
    "        # pred.append(out.argmax(dim=1))  # Use the class with highest probability.\n",
    "\n",
    "    return np.concatenate(pred, axis=0)  # Derive ratio of correct predictions. , proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9c2562d-305c-422f-95a5-44fcc4e6eb5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T22:55:44.265629Z",
     "iopub.status.busy": "2023-01-22T22:55:44.264873Z",
     "iopub.status.idle": "2023-01-22T22:55:47.160489Z",
     "shell.execute_reply": "2023-01-22T22:55:47.159693Z",
     "shell.execute_reply.started": "2023-01-22T22:55:44.265602Z"
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    predictions = predict(pred_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "68761999-08ae-4dab-8747-a82dca5ffb0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T22:35:34.249484Z",
     "iopub.status.busy": "2023-01-21T22:35:34.248979Z",
     "iopub.status.idle": "2023-01-21T22:35:34.261432Z",
     "shell.execute_reply": "2023-01-21T22:35:34.260904Z",
     "shell.execute_reply.started": "2023-01-21T22:35:34.249463Z"
    }
   },
   "outputs": [],
   "source": [
    "def submit(y_pred_proba):\n",
    "    # Write predictions to a file\n",
    "    with open(\n",
    "        \"../Submissions/geometric_GCNcov_150_param__1.17_loss.csv\", \"w\"\n",
    "    ) as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=\",\")\n",
    "        lst = list()\n",
    "        for i in range(18):\n",
    "            lst.append(\"class\" + str(i))\n",
    "        lst.insert(0, \"name\")\n",
    "        writer.writerow(lst)\n",
    "        for i, protein in enumerate(proteins_test):\n",
    "            lst = y_pred_proba[i, :].tolist()\n",
    "            lst.insert(0, protein)\n",
    "            writer.writerow(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "433f567b-2a08-436c-9f79-71f195effcdd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T22:56:08.394905Z",
     "iopub.status.busy": "2023-01-22T22:56:08.394125Z",
     "iopub.status.idle": "2023-01-22T22:56:08.432049Z",
     "shell.execute_reply": "2023-01-22T22:56:08.431529Z",
     "shell.execute_reply.started": "2023-01-22T22:56:08.394871Z"
    }
   },
   "outputs": [],
   "source": [
    "submit(predictions, \"GCN_fINal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2b56a2aa-9d94-4880-9ada-91778ebb889d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f526ddf0-c6d6-4da4-b908-082208350f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
