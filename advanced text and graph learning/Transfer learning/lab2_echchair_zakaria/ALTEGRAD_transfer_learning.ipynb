{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlAfI8mCWAf3"
      },
      "source": [
        "<center><h2>ALTeGraD 2022<br>Lab Session 2: Transfer learning for NLP</h2> 27 / 10 / 2022<br> M. Kamal Eddine, H. Abdine<br><br>\n",
        "\n",
        "\n",
        "<b>Student name:</b> [fill me]\n",
        "\n",
        "</center>\n",
        "\n",
        "<br><br>\n",
        "In this lab we will:\n",
        "* Implement and pretrain a language model with transformer architecture.\n",
        "* Use the pretrained model (transfer learning) to perform a sentiment analysis task which consists of classifying some books reviews into positive and negative ones.\n",
        "* Compare the performance of the pretrained model to a model trained from scratch.\n",
        " <br>\n",
        " \n",
        "<b>The deadline for this lab is November 14, 2022 11:59 PM.</b> More details about the submission and the architecture for this lab can be found in the handout PDF."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "IqukuIe0Rb_c"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FF6fjkqgN39"
      },
      "source": [
        "### The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "p0cj9WkSFQwl"
      },
      "outputs": [],
      "source": [
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, ntoken, nhead, nhid, nlayers, dropout=0.5):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        '''\n",
        "        ntokens: the size of vocabulary\n",
        "        nhid: the hidden dimension of the model.\n",
        "        We assume that embedding_dim = nhid\n",
        "        nlayers: the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "        nhead: the number of heads in the multiheadattention models\n",
        "        dropout: the dropout value\n",
        "         '''\n",
        "        self.model_type = \"Transformer\"\n",
        "        self.encoder = nn.Embedding(ntoken, nhid) # fill me, nhid = the dim_embed\n",
        "        self.pos_encoder = PositionalEncoding(nhid, dropout) #fill me, the PositionalEncoding class is implemented in the next cell\n",
        "        encoder_layers = nn.TransformerEncoderLayer(nhid, nhead, nhid, dropout) #fill me we assume nhid = d_model = dim_feedforward\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, nlayers) #fill me\n",
        "        self.nhid = nhid\n",
        "        self.init_weights()\n",
        "\n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = (\n",
        "            mask.float()\n",
        "            .masked_fill(mask == 0, float(\"-inf\"))\n",
        "            .masked_fill(mask == 1, float(0.0))\n",
        "        )\n",
        "        return mask\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        src = self.encoder(src) * math.sqrt(self.nhid) \n",
        "        src = self.pos_encoder(src)\n",
        "        output = self.transformer_encoder(src, src_mask)\n",
        "        return output\n",
        "\n",
        "\n",
        "class ClassificationHead(nn.Module):\n",
        "    def __init__(self, nhid, nclasses):\n",
        "        super(ClassificationHead, self).__init__()\n",
        "        self.decoder = nn.Linear(nhid, nclasses)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.decoder.bias.data.zero_()\n",
        "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src):\n",
        "        output = self.decoder(src)\n",
        "        return output\n",
        "    \n",
        "class Model(nn.Module):\n",
        "    def __init__(self, ntoken, nhead, nhid, nlayers, nclasses, dropout=0.5):\n",
        "        super(Model, self).__init__()\n",
        "        self.base = TransformerModel(ntoken, nhead, nhid, nlayers, dropout=0.5)\n",
        "        self.classifier = ClassificationHead(nhid, nclasses)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        # base model\n",
        "        x = self.base.forward(src, src_mask)\n",
        "        # classifier model\n",
        "        output = self.classifier(x)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "kt2QQohaFZry"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, nhid, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, nhid)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(\n",
        "            torch.arange(0, nhid, 2).float() * (-math.log(10000.0) / nhid)\n",
        "        )\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[: x.size(0), :]\n",
        "        return self.dropout(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfEYHJx2JW6l"
      },
      "source": [
        "Let's verify if our model works, by applying one inference step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhb2gkUhJMR0",
        "outputId": "4634d513-504b-4373-99db-585f526a134d",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 6, 100])\n"
          ]
        }
      ],
      "source": [
        "ntokens = 100 # the size of vocabulary\n",
        "nhid = 200  # hidden dimension\n",
        "nlayers = 4  # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "nhead = 2  # the number of heads in the multiheadattention models\n",
        "dropout = 0  # the dropout value\n",
        "\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens, dropout).to(device)\n",
        "dummy_input = torch.tensor([[2, 6, 2, 5, 43, 21]]).to(device)\n",
        "src_mask = model.base.generate_square_subsequent_mask(1).to(device)\n",
        "out = model.forward(dummy_input, src_mask)\n",
        "\n",
        "print(out.shape) # is it the right shape?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIs2FiX9Jvqx",
        "outputId": "8fbad9a9-8a1a-499c-835d-4b1f6c4ebd8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of params for the base model: 988000\n",
            "Number of params for the classifier model: 20100\n"
          ]
        }
      ],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(\"Number of params for the base model:\", count_parameters(model.base))\n",
        "print(\"Number of params for the classifier model:\", count_parameters(model.classifier))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i74NN897Fcit"
      },
      "source": [
        "## Vocabulary and Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qjd26ghWuff",
        "outputId": "2828b8d9-d29b-446e-8025-99d60f3d7022",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-12 19:50:09--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/dict.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 577587 (564K) [text/plain]\n",
            "Saving to: ‘dict.txt.2’\n",
            "\n",
            "dict.txt.2          100%[===================>] 564.05K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2022-11-12 19:50:09 (13.6 MB/s) - ‘dict.txt.2’ saved [577587/577587]\n",
            "\n",
            "▁d 1\n",
            "es 1\n",
            "▁l 1\n",
            "en 1\n",
            "on 1\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/dict.txt\n",
        "!head -5 dict.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFdH_-JeFbGA",
        "outputId": "ab558a9c-32f2-414d-9c19-4d36875c8761"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▁trop\n"
          ]
        }
      ],
      "source": [
        "path_vocab = \"dict.txt\"\n",
        "token2ind = {\"<sos>\": 0, \"<pad>\": 1, \"<eos>\": 2, \"<oov>\": 3} # the 4 first indices are reserved to special tokens\n",
        "with open(path_vocab, \"r\", encoding=\"utf8\") as f:\n",
        "    for idx, line in enumerate(f):\n",
        "        word = line.split()[0].strip()\n",
        "        if word not in token2ind: \n",
        "            token2ind[word] = idx + 4 \n",
        "\n",
        "ind2token = {value: key for key, value in token2ind.items()}\n",
        "\n",
        "print(ind2token[1111])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOExGODajN8p"
      },
      "source": [
        "### Data Loader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Y0jN-Ar9i5Q1"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "\n",
        "class Dataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        path_documents,\n",
        "        path_labels=None,\n",
        "        token2ind={},\n",
        "        max_len=512,\n",
        "        task=\"language_modeling\",\n",
        "    ):\n",
        "        self.task = task\n",
        "        self.max_len = max_len\n",
        "        self.token2ind = token2ind\n",
        "        self.documents = []\n",
        "        self.labels = []\n",
        "        with open(path_documents, \"r\", encoding=\"utf8\") as f1:\n",
        "            for line in f1:\n",
        "                self.documents.append(line.strip())\n",
        "        if task == \"classification\":\n",
        "            with open(path_labels, \"r\", encoding=\"utf8\") as f1:\n",
        "                for line in f1:\n",
        "                    self.labels.append(int(line.strip()))\n",
        "            assert len(self.labels) == len(self.documents)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.documents)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sequence = self.documents[index].split()\n",
        "        if len(sequence) > self.max_len - 1:\n",
        "            sequence = sequence[: self.max_len - 1]\n",
        "        source_sequence = [token2ind[\"<sos>\"]] + [token2ind.get(word, token2ind[\"<oov>\"]) for word in sequence] #fill me (constract the input sequence using token2ind, sequence and special tokens)\n",
        "        if self.task == \"language_modeling\":\n",
        "            target = source_sequence[1:]\n",
        "            target.append(self.token2ind[\"<eos>\"])\n",
        "        elif self.task == \"classification\":\n",
        "            target = [self.labels[index]]\n",
        "        sample = {\n",
        "            \"source_sequence\": torch.tensor(source_sequence),\n",
        "            \"target\": torch.tensor(target),\n",
        "        }\n",
        "        return sample\n",
        "\n",
        "\n",
        "def MyCollator(batch):\n",
        "    source_sequences = pad_sequence(\n",
        "        #we use padding to match the length of the sequences in the same batch\n",
        "        [sample[\"source_sequence\"] for sample in batch], padding_value=token2ind[\"<pad>\"]\n",
        "    )\n",
        "    target = pad_sequence(\n",
        "        [sample[\"target\"] for sample in batch], padding_value=token2ind[\"<pad>\"]\n",
        "    )\n",
        "    return source_sequences, target.reshape(-1)\n",
        "\n",
        "\n",
        "def get_loader(\n",
        "    path_documents,\n",
        "    path_labels=None,\n",
        "    token2ind={},\n",
        "    max_len=512,\n",
        "    batch_size=32,\n",
        "    task=\"language_modeling\",\n",
        "):\n",
        "    dataset = Dataset(\n",
        "        path_documents,\n",
        "        path_labels=path_labels,\n",
        "        token2ind=token2ind,\n",
        "        max_len=512,\n",
        "        task=task,\n",
        "    )\n",
        "    data_loader = DataLoader(\n",
        "        dataset=dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        collate_fn=MyCollator,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "    return data_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTns4lHrjUTa"
      },
      "source": [
        "## The Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "4_jwosiLjRsS"
      },
      "outputs": [],
      "source": [
        "def train(\n",
        "    path_data_train,\n",
        "    path_labels_train=None,\n",
        "    path_data_valid=None,\n",
        "    save_interval=-1,\n",
        "    log_interval=5,\n",
        "    task=\"language_modeling\",\n",
        "    batch_size=32,\n",
        "):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    ntokens = len(token2ind)\n",
        "    data_loader = get_loader(\n",
        "        path_data_train,\n",
        "        path_labels_train,\n",
        "        token2ind,\n",
        "        task=task,\n",
        "        batch_size=batch_size,\n",
        "    )\n",
        "    \n",
        "    losses = []\n",
        "    for idx, data in enumerate(data_loader): #step 1\n",
        "        optimizer.zero_grad()\n",
        "        src_mask = model.base.generate_square_subsequent_mask(data[0].size(0)).to(\n",
        "            device\n",
        "        )\n",
        "\n",
        "        input = data[0].to(device)\n",
        "        output = model(input, src_mask) #step 2 maybe we need to use .base\n",
        "        if task == 'classification':\n",
        "            #last vector only\n",
        "            output = model.forward(input, src_mask)[-1]\n",
        "        output = output.view(-1, output.shape[-1])\n",
        "        target =  data[1]\n",
        "        target = target.to(device)\n",
        "        loss = criterion(output, target) #fill me, Cross entropy check next cells\n",
        "        #fill me step 3\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5) # prevent exploding gradient \n",
        "        #fill me step 4\n",
        "        optimizer.step() \n",
        "        total_loss += loss.item() \n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            cur_loss = total_loss / log_interval\n",
        "            print(\n",
        "                \"| epoch {:3d} | {:5d}/{:5d} steps | \"\n",
        "                \"loss {:5.5f} | ppl {:8.3f}\".format(\n",
        "                    epoch, idx, len(data_loader), cur_loss, math.exp(cur_loss),\n",
        "                )\n",
        "            )\n",
        "            losses.append(cur_loss)\n",
        "            total_loss = 0\n",
        "    return losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "pgf6BDB9jUr6"
      },
      "outputs": [],
      "source": [
        "ntokens = len(token2ind) #fill me # the size of vocabulary\n",
        "nhid = 200  # the dimension of the feedforward network model in nn.TransformerEncoder\n",
        "nlayers = 4  # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "nhead = 2  # the number of heads in the multiheadattention models\n",
        "dropout = 0  # the dropout value\n",
        "\n",
        "nclasses = 2 # for classification task only\n",
        "\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens, dropout).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "u-OLy4KIkDwf"
      },
      "outputs": [],
      "source": [
        "# optimization paramerters\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=token2ind['<pad>'])\n",
        "lr = 0.0003  # learning rate\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bwh3n9xZQy4e",
        "outputId": "59c00c74-f299-4e34-9a35-ff5580f9ffcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-12 19:50:10--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretraining_subset.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10146460 (9.7M) [text/plain]\n",
            "Saving to: ‘pretraining_subset.txt.2’\n",
            "\n",
            "\rpretraining_subset.   0%[                    ]       0  --.-KB/s               \rpretraining_subset. 100%[===================>]   9.68M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2022-11-12 19:50:10 (108 MB/s) - ‘pretraining_subset.txt.2’ saved [10146460/10146460]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretraining_subset.txt\n",
        "path_data_train = \"pretraining_subset.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "0m11g4ScjZaR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "726ab22a-068b-4e2c-cc50-96ba47f200d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   500/ 3125 steps | loss 7.71900 | ppl 2250.700\n",
            "| epoch   1 |  1000/ 3125 steps | loss 7.05630 | ppl 1160.144\n",
            "| epoch   1 |  1500/ 3125 steps | loss 6.76946 | ppl  870.842\n",
            "| epoch   1 |  2000/ 3125 steps | loss 6.59556 | ppl  731.840\n",
            "| epoch   1 |  2500/ 3125 steps | loss 6.45904 | ppl  638.448\n",
            "| epoch   1 |  3000/ 3125 steps | loss 6.37056 | ppl  584.383\n",
            "| epoch   2 |   500/ 3125 steps | loss 6.17621 | ppl  481.165\n",
            "| epoch   2 |  1000/ 3125 steps | loss 6.09060 | ppl  441.685\n",
            "| epoch   2 |  1500/ 3125 steps | loss 6.06822 | ppl  431.913\n",
            "| epoch   2 |  2000/ 3125 steps | loss 6.04367 | ppl  421.438\n",
            "| epoch   2 |  2500/ 3125 steps | loss 5.98303 | ppl  396.640\n",
            "| epoch   2 |  3000/ 3125 steps | loss 5.94890 | ppl  383.331\n"
          ]
        }
      ],
      "source": [
        "#pretraining on a tiny subset\n",
        "log_interval = 500\n",
        "epochs = 2\n",
        "for epoch in range(1, epochs + 1): #5\n",
        "    train(\n",
        "        path_data_train,\n",
        "        save_interval=-1,\n",
        "        task=\"language_modeling\", # fill me\n",
        "        batch_size=16,\n",
        "        log_interval=log_interval,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeOM1dOvkO4e"
      },
      "source": [
        "## Text Generation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "-BcBC6FSkMH3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b20d3f53-3ac4-40cc-e959-3d237230d020"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-12 19:55:23--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretrained_model_4layers.pt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 88093955 (84M) [application/octet-stream]\n",
            "Saving to: ‘pretrained_model_4layers.pt.1’\n",
            "\n",
            "pretrained_model_4l 100%[===================>]  84.01M   214MB/s    in 0.4s    \n",
            "\n",
            "2022-11-12 19:55:23 (214 MB/s) - ‘pretrained_model_4layers.pt.1’ saved [88093955/88093955]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretrained_model_4layers.pt\n",
        "\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens).to(device) \n",
        "\n",
        "#load the checkpoint\n",
        "checkpoint = torch.load('pretrained_model_4layers.pt') \n",
        "#load state dict\n",
        "model.load_state_dict(checkpoint['model_state_dict']) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Y37mRtQeIVa",
        "outputId": "358ef504-9679-4a4c-8077-4f9bd7cf05f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.97)\n"
          ]
        }
      ],
      "source": [
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBRRVsWqlIoQ",
        "outputId": "884859e7-65dc-4017-d8ef-59ebd9d05e3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-12 19:55:28--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/sentencepiece.french.model\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115362 (1.1M) [application/octet-stream]\n",
            "Saving to: ‘sentencepiece.french.model.1’\n",
            "\n",
            "sentencepiece.frenc 100%[===================>]   1.06M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2022-11-12 19:55:28 (21.2 MB/s) - ‘sentencepiece.french.model.1’ saved [1115362/1115362]\n",
            "\n",
            "['▁Bonjour', '▁les', '▁amis', '!']\n",
            "Bonjour les amis!\n"
          ]
        }
      ],
      "source": [
        "# !pip install sentencepiece   # uncomment this if you are using google colab\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/sentencepiece.french.model\n",
        "\n",
        "import sentencepiece as spm\n",
        "\n",
        "s = spm.SentencePieceProcessor(model_file='sentencepiece.french.model') #load sentencepiece model\n",
        "\n",
        "#examples\n",
        "encoded = s.encode_as_pieces(\"Bonjour les amis!\")\n",
        "decoded = s.decode_pieces(encoded)\n",
        "print(encoded)\n",
        "print(decoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "TtLlV05pkQI3"
      },
      "outputs": [],
      "source": [
        "def infer_next_token(sent):\n",
        "    model.eval()\n",
        "    sent_pieces = s.encode_as_pieces(sent)\n",
        "    source = [token2ind['<sos>']] + [token2ind[el] for el in sent_pieces] # list of tokens\n",
        "    source = torch.tensor(source).to(device)\n",
        "    source = source.reshape(-1, 1)\n",
        "    src_mask = model.base.generate_square_subsequent_mask(source.size(0)).to(device)\n",
        "    out = model(source, src_mask)\n",
        "    next_token_ind = torch.sigmoid(out.squeeze())[-1].argmax().item()\n",
        "    return next_token_ind, out\n",
        "    \n",
        "def infer_next_tokens(sent, max_len=50):\n",
        "    all_tokens = s.encode_as_pieces(sent)\n",
        "    for i in range(max_len):\n",
        "        index = infer_next_token(s.decode_pieces(all_tokens))[0]\n",
        "        if index == 2:\n",
        "            break\n",
        "        all_tokens.append(ind2token[index])\n",
        "    return s.decode_pieces(all_tokens)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "f83Nn5nSly4v",
        "outputId": "0115c6d0-1454-4bca-897d-bed187fb2a61"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Bonjour les gens qui ont été très accueillants et sympathiques.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "sent = \"Bonjour les\"\n",
        "infer_next_tokens(sent)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lp7mjVzomoZ3"
      },
      "source": [
        "### Supervised task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0K1BZsblmEmx",
        "outputId": "34b6c0ab-9fd8-42fb-88b4-d0b8d49e24be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-12 19:55:29--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.review.spm\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1495960 (1.4M) [text/plain]\n",
            "Saving to: ‘train.review.spm.1’\n",
            "\n",
            "train.review.spm.1  100%[===================>]   1.43M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2022-11-12 19:55:29 (25.6 MB/s) - ‘train.review.spm.1’ saved [1495960/1495960]\n",
            "\n",
            "--2022-11-12 19:55:29--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.label\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3200 (3.1K) [text/plain]\n",
            "Saving to: ‘train.label.1’\n",
            "\n",
            "train.label.1       100%[===================>]   3.12K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-11-12 19:55:29 (35.0 MB/s) - ‘train.label.1’ saved [3200/3200]\n",
            "\n",
            "--2022-11-12 19:55:29--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.review.spm\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1864544 (1.8M) [text/plain]\n",
            "Saving to: ‘test.review.spm.1’\n",
            "\n",
            "test.review.spm.1   100%[===================>]   1.78M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2022-11-12 19:55:30 (31.0 MB/s) - ‘test.review.spm.1’ saved [1864544/1864544]\n",
            "\n",
            "--2022-11-12 19:55:30--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.label\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4000 (3.9K) [text/plain]\n",
            "Saving to: ‘test.label.1’\n",
            "\n",
            "test.label.1        100%[===================>]   3.91K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-11-12 19:55:30 (60.4 MB/s) - ‘test.label.1’ saved [4000/4000]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.review.spm\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.label\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.review.spm\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.label\n",
        "\n",
        "path_data_train = \"train.review.spm\"\n",
        "path_labels_train = \"train.label\"\n",
        "\n",
        "path_data_valid = \"test.review.spm\"\n",
        "path_labels_valid = \"test.label\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "_MLfvjiom2SL"
      },
      "outputs": [],
      "source": [
        "# a function to evaluate the validation accuracy of the model.\n",
        "def evaluate_accuracy(data_loader):\n",
        "    #to be implemented\n",
        "    model.eval()\n",
        "    acc = []\n",
        "    for idx, data in enumerate(data_loader): #step 1\n",
        "        src_mask = model.base.generate_square_subsequent_mask(data[0].size(0)).to(device)\n",
        "        input = data[0].to(device)\n",
        "        output = model.forward(input, src_mask)[-1] \n",
        "        output = output.view(-1, output.shape[-1])\n",
        "        target =  data[1]\n",
        "        target = target.to(device)\n",
        "        num_corrects = ((torch.argmax(torch.sigmoid(output), dim=1) > 0.5) == target).sum().item()\n",
        "        acc.append(100.0 * num_corrects/len(target))\n",
        "\n",
        "    return np.mean(acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "qzmx7T7xoa6v"
      },
      "outputs": [],
      "source": [
        "#save the base model to be loaded later in the fine-tuning phase\n",
        "torch.save({\"model_state_dict\": model.base.state_dict(),}, \"pretrained_model_4layers_no_class_head.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-xclMCpnVpw",
        "outputId": "b5c6d884-45db-46de-f638-aa25582086eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=====Trainig FROM SCRATCH======\n",
            "| epoch   1 |    50/  200 steps | loss 0.85885 | ppl    2.360\n",
            "| epoch   1 |   100/  200 steps | loss 0.74841 | ppl    2.114\n",
            "| epoch   1 |   150/  200 steps | loss 0.80351 | ppl    2.233\n",
            "| epoch   2 |    50/  200 steps | loss 0.73458 | ppl    2.085\n",
            "| epoch   2 |   100/  200 steps | loss 0.76706 | ppl    2.153\n",
            "| epoch   2 |   150/  200 steps | loss 0.72952 | ppl    2.074\n",
            "| epoch   3 |    50/  200 steps | loss 0.73840 | ppl    2.093\n",
            "| epoch   3 |   100/  200 steps | loss 0.72757 | ppl    2.070\n",
            "| epoch   3 |   150/  200 steps | loss 0.70091 | ppl    2.016\n",
            "| epoch   4 |    50/  200 steps | loss 0.74755 | ppl    2.112\n",
            "| epoch   4 |   100/  200 steps | loss 0.66585 | ppl    1.946\n",
            "| epoch   4 |   150/  200 steps | loss 0.65325 | ppl    1.922\n",
            "| epoch   5 |    50/  200 steps | loss 0.63321 | ppl    1.884\n",
            "| epoch   5 |   100/  200 steps | loss 0.53050 | ppl    1.700\n",
            "| epoch   5 |   150/  200 steps | loss 0.52252 | ppl    1.686\n",
            "| epoch   6 |    50/  200 steps | loss 0.42265 | ppl    1.526\n",
            "| epoch   6 |   100/  200 steps | loss 0.57226 | ppl    1.772\n",
            "| epoch   6 |   150/  200 steps | loss 0.47916 | ppl    1.615\n",
            "| epoch   7 |    50/  200 steps | loss 0.33020 | ppl    1.391\n",
            "| epoch   7 |   100/  200 steps | loss 0.33089 | ppl    1.392\n",
            "| epoch   7 |   150/  200 steps | loss 0.26247 | ppl    1.300\n",
            "| epoch   8 |    50/  200 steps | loss 0.23307 | ppl    1.262\n",
            "| epoch   8 |   100/  200 steps | loss 0.19815 | ppl    1.219\n",
            "| epoch   8 |   150/  200 steps | loss 0.28107 | ppl    1.325\n",
            "| epoch   9 |    50/  200 steps | loss 0.21481 | ppl    1.240\n",
            "| epoch   9 |   100/  200 steps | loss 0.26054 | ppl    1.298\n",
            "| epoch   9 |   150/  200 steps | loss 0.23459 | ppl    1.264\n",
            "| epoch  10 |    50/  200 steps | loss 0.24901 | ppl    1.283\n",
            "| epoch  10 |   100/  200 steps | loss 0.16046 | ppl    1.174\n",
            "| epoch  10 |   150/  200 steps | loss 0.27374 | ppl    1.315\n",
            "| epoch  11 |    50/  200 steps | loss 0.16715 | ppl    1.182\n",
            "| epoch  11 |   100/  200 steps | loss 0.14094 | ppl    1.151\n",
            "| epoch  11 |   150/  200 steps | loss 0.11606 | ppl    1.123\n",
            "| epoch  12 |    50/  200 steps | loss 0.09158 | ppl    1.096\n",
            "| epoch  12 |   100/  200 steps | loss 0.18027 | ppl    1.198\n",
            "| epoch  12 |   150/  200 steps | loss 0.11615 | ppl    1.123\n",
            "| epoch  13 |    50/  200 steps | loss 0.13327 | ppl    1.143\n",
            "| epoch  13 |   100/  200 steps | loss 0.11720 | ppl    1.124\n",
            "| epoch  13 |   150/  200 steps | loss 0.19146 | ppl    1.211\n",
            "| epoch  14 |    50/  200 steps | loss 0.10023 | ppl    1.105\n",
            "| epoch  14 |   100/  200 steps | loss 0.05341 | ppl    1.055\n",
            "| epoch  14 |   150/  200 steps | loss 0.10187 | ppl    1.107\n",
            "| epoch  15 |    50/  200 steps | loss 0.05223 | ppl    1.054\n",
            "| epoch  15 |   100/  200 steps | loss 0.15172 | ppl    1.164\n",
            "| epoch  15 |   150/  200 steps | loss 0.04548 | ppl    1.047\n",
            "\n",
            "=====PRETRAINED MODEL======\n",
            "| epoch   1 |    50/  200 steps | loss 0.88442 | ppl    2.422\n",
            "| epoch   1 |   100/  200 steps | loss 0.82364 | ppl    2.279\n",
            "| epoch   1 |   150/  200 steps | loss 0.73529 | ppl    2.086\n",
            "| epoch   2 |    50/  200 steps | loss 0.71810 | ppl    2.051\n",
            "| epoch   2 |   100/  200 steps | loss 0.63127 | ppl    1.880\n",
            "| epoch   2 |   150/  200 steps | loss 0.63722 | ppl    1.891\n",
            "| epoch   3 |    50/  200 steps | loss 0.61208 | ppl    1.844\n",
            "| epoch   3 |   100/  200 steps | loss 0.57939 | ppl    1.785\n",
            "| epoch   3 |   150/  200 steps | loss 0.54782 | ppl    1.729\n",
            "| epoch   4 |    50/  200 steps | loss 0.50629 | ppl    1.659\n",
            "| epoch   4 |   100/  200 steps | loss 0.57324 | ppl    1.774\n",
            "| epoch   4 |   150/  200 steps | loss 0.53270 | ppl    1.704\n",
            "| epoch   5 |    50/  200 steps | loss 0.52186 | ppl    1.685\n",
            "| epoch   5 |   100/  200 steps | loss 0.48523 | ppl    1.625\n",
            "| epoch   5 |   150/  200 steps | loss 0.52147 | ppl    1.685\n",
            "| epoch   6 |    50/  200 steps | loss 0.50416 | ppl    1.656\n",
            "| epoch   6 |   100/  200 steps | loss 0.43641 | ppl    1.547\n",
            "| epoch   6 |   150/  200 steps | loss 0.48716 | ppl    1.628\n",
            "| epoch   7 |    50/  200 steps | loss 0.47693 | ppl    1.611\n",
            "| epoch   7 |   100/  200 steps | loss 0.41987 | ppl    1.522\n",
            "| epoch   7 |   150/  200 steps | loss 0.44505 | ppl    1.561\n",
            "| epoch   8 |    50/  200 steps | loss 0.44836 | ppl    1.566\n",
            "| epoch   8 |   100/  200 steps | loss 0.36326 | ppl    1.438\n",
            "| epoch   8 |   150/  200 steps | loss 0.44469 | ppl    1.560\n",
            "| epoch   9 |    50/  200 steps | loss 0.31965 | ppl    1.377\n",
            "| epoch   9 |   100/  200 steps | loss 0.41547 | ppl    1.515\n",
            "| epoch   9 |   150/  200 steps | loss 0.41529 | ppl    1.515\n",
            "| epoch  10 |    50/  200 steps | loss 0.33715 | ppl    1.401\n",
            "| epoch  10 |   100/  200 steps | loss 0.38033 | ppl    1.463\n",
            "| epoch  10 |   150/  200 steps | loss 0.38199 | ppl    1.465\n",
            "| epoch  11 |    50/  200 steps | loss 0.35464 | ppl    1.426\n",
            "| epoch  11 |   100/  200 steps | loss 0.35824 | ppl    1.431\n",
            "| epoch  11 |   150/  200 steps | loss 0.46369 | ppl    1.590\n",
            "| epoch  12 |    50/  200 steps | loss 0.34089 | ppl    1.406\n",
            "| epoch  12 |   100/  200 steps | loss 0.32307 | ppl    1.381\n",
            "| epoch  12 |   150/  200 steps | loss 0.37875 | ppl    1.460\n",
            "| epoch  13 |    50/  200 steps | loss 0.45212 | ppl    1.572\n",
            "| epoch  13 |   100/  200 steps | loss 0.28262 | ppl    1.327\n",
            "| epoch  13 |   150/  200 steps | loss 0.38100 | ppl    1.464\n",
            "| epoch  14 |    50/  200 steps | loss 0.33418 | ppl    1.397\n",
            "| epoch  14 |   100/  200 steps | loss 0.28262 | ppl    1.327\n",
            "| epoch  14 |   150/  200 steps | loss 0.36306 | ppl    1.438\n",
            "| epoch  15 |    50/  200 steps | loss 0.27635 | ppl    1.318\n",
            "| epoch  15 |   100/  200 steps | loss 0.37738 | ppl    1.458\n",
            "| epoch  15 |   150/  200 steps | loss 0.25317 | ppl    1.288\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from_scratch_settings = [True, False]\n",
        "\n",
        "from_scratch_valid_acc = []\n",
        "pretrained_valid_acc = []\n",
        "lr = 0.0001\n",
        "\n",
        "for from_scratch in from_scratch_settings:\n",
        "    model = Model(ntokens, nhead, nhid, nlayers, 2, dropout).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    if not from_scratch:\n",
        "        print(\"=====PRETRAINED MODEL======\")\n",
        "        #load checkpoint\n",
        "        checkpoint = torch.load(\"pretrained_model_4layers_no_class_head.pt\")\n",
        "        #load state dict\n",
        "        model.base.load_state_dict(checkpoint['model_state_dict'])\n",
        "    else:\n",
        "        print(\"=====Trainig FROM SCRATCH======\")\n",
        "    epochs = 15\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train(\n",
        "            path_data_train,\n",
        "            path_labels_train,\n",
        "            save_interval=-1,\n",
        "            task='classification',\n",
        "            batch_size=8,\n",
        "            log_interval=50,\n",
        "        )\n",
        "        acc = evaluate_accuracy(\n",
        "            get_loader(\n",
        "                path_data_valid,\n",
        "                path_labels_valid,\n",
        "                token2ind=token2ind,\n",
        "                batch_size=20,\n",
        "                task='classification',\n",
        "            )\n",
        "        )\n",
        "        if from_scratch:\n",
        "            from_scratch_valid_acc.append(acc)\n",
        "        else:\n",
        "            pretrained_valid_acc.append(acc)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "AkdKyiLy1CRM"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "RCpBIdTHojm6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "outputId": "00909a41-a1a5-4b52-864d-ae2c464f0d25"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#Visualize the accuracy\n",
        "fig = plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, 16), [acc.item() for acc in from_scratch_valid_acc], label='from scratch')\n",
        "plt.plot(range(1, 16), [acc.item() for acc in pretrained_valid_acc], label='pretrained')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy %')\n",
        "plt.legend()\n",
        "plt.plot()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bNPc5VNF9Eqa"
      },
      "execution_count": 37,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "1f3cfdeab8dd8f9900bd16266619de191cf0f5e09365d74b1fba1714dce58066"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}