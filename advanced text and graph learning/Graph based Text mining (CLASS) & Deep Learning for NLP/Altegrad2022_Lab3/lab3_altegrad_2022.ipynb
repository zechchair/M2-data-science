{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<center><h2>ALTeGraD 2022<br>Lab Session 3: NLP Frameworks</h2> 15 / 11 / 2022<br> M. Kamal Eddine, H. Abdine<br><br>\n",
        "\n",
        "\n",
        "<b>Student name:</b> [fill me]\n",
        "\n",
        "</center>\n",
        "\n",
        "In this lab you will learn how to use Fairseq and HuggingFace transformers - The most used libraries by researchers and developers to pretrain and finetune language models - to finetune a pretrained French language model ($RoBERTa_{small}^{fr}$) on the sentiment analysis dataset CLS_Books where each review is labeled as positive or negative.\n",
        "\n",
        "In the first part of this lab, you will finetune the given model on model on CLS_Books dataset using <b>Fairseq</b> by following these steps:<br>\n",
        "\n",
        " 1- <b>Tokenize the reviews</b> (Train, Valid and Test) using trained sentencepiece tokenizer provided alongside the pretrained model.[using sentencepiece library and setting the parameter <b>out_type=str</b> in the encode function].<br>\n",
        " 2- <b>Binarize the tokenized reviews and their labels</b> using the preprocess python script provided in Fairseq.<br>\n",
        " 3- <b>Fintune the pretrained $RoBERTa_{small}^{fr}$ model</b> using the train python script provided in Fairseq.<br>\n",
        " \n",
        " Finally, you will finish the first part by training a random $RoBERTa_{small}^{fr}$ model on the CLS_Books dataset and compare the results against the pretrained model while <b>visualizing the accuracies on tensorboard</b>.\n",
        "\n",
        " In the second part of this lab, you will use <b>HuggingFace's transformers</b> library to perform the finrtuning done previously with Fairseq.\n",
        "\n"
      ],
      "metadata": {
        "id": "DsD-LMKT7XMt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <b>Part 1: Fairseq</b>"
      ],
      "metadata": {
        "id": "H40TxVIvEWyu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <b>Preparing the environment and installing libraries, model and data</b>\n",
        "\n",
        "In this section, we will setup the environment on Google Colab (first cell), download the pretraind model (second cell) and the finetuning dataset (third cell). In case you are using your personal computer maket sure to:\n",
        "\n",
        "1- Use Ubuntu (or any similar linux distribution) or MacOS. <b> P.S. In case you have Windows, please use Google Colab. We won't respond to any question regarding errors on Windows. </b>\n",
        "\n",
        "2- <b>Use Anaconda</b> and create new environment if you already installed Fairseq since we will be using a slightly modified version of this library.\n",
        "\n",
        "3- <b>Do not run the following three cells</b>. Instead, use their content on your personal command line."
      ],
      "metadata": {
        "id": "GwN3KCm5Ec6r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir altegrad.lab3 && cd altegrad.lab3 && mkdir libs \n",
        "%cd altegrad.lab3/libs\n",
        "!git clone https://github.com/hadi-abdine/fairseq\n",
        "!pip install git+https://github.com/hadi-abdine/fairseq\n",
        "!git clone https://github.com/huggingface/transformers.git\n",
        "!pip install git+https://github.com/huggingface/transformers.git\n",
        "!pip install datasets\n",
        "!pip install evaluate\n",
        "!pip install sentencepiece\n",
        "!pip install tensorboardX\n",
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "6cGqZ9ZB84Cd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd .. && mkdir models \n",
        "%cd ../models\n",
        "!wget -c \"https://onedrive.live.com/download?cid=AE69638675180117&resid=AE69638675180117%21267604&authkey=ANaaKIDigQPyJlM\" -O \"model_fairseq.zip\"\n",
        "!unzip model_fairseq.zip\n",
        "!rm model_fairseq.zip\n",
        "!rm -rf __MACOSX/"
      ],
      "metadata": {
        "id": "rxHffsPm-EqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd .. && mkdir data\n",
        "%cd ../data\n",
        "!wget -c \"https://onedrive.live.com/download?cid=AE69638675180117&resid=AE69638675180117%21267606&authkey=AA8Td6LoeijplD4\" -O \"cls.books.zip\"\n",
        "!unzip cls.books.zip\n",
        "!rm cls.books.zip\n",
        "!rm -rf __MACOSX/\n",
        "%cd .."
      ],
      "metadata": {
        "id": "HfZ_znATNdya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <b> Number of parameters of the model</b>\n",
        "\n",
        "In this section you have to compute the number of parameters of $RoBERTa_{small}^{fr}$ using PyTorch. (<b>Hint:</b> you can check the architecture of the model using model['model'])"
      ],
      "metadata": {
        "id": "TvpyZEexOXHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "n_parameters = 0\n",
        "model = torch.load(\"models/RoBERTa_small_fr/model.pt\")\n",
        "# your code here\n",
        "\n",
        "print(n_parameters)"
      ],
      "metadata": {
        "id": "j7isz60LOwlV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <b>Tokenizing the reviews</b>\n",
        "\n",
        "In this section we will tokenize the finetuning dataset using sentenpiece tokenizer. We have three splits in our datase: train valid and test sets. \n",
        "\n",
        "In this task you have to use the trained sentencepiece tokenizer (RoBERTa_small_fr/sentencepiece.bpe.model) to tokenize the three files <b>train.review</b>, <b>valid.review</b> and <b>test.review</b> and output the three files <b>train.spm.review</b>, <b>valid.spm.review</b> and <b>test.spm.review</b> containing the tokenized reviews."
      ],
      "metadata": {
        "id": "gz8fnWOSI0eF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sentencepiece as spm\n",
        "s = spm.SentencePieceProcessor(model_file='models/RoBERTa_small_fr/sentencepiece.bpe.model')\n",
        "\n",
        "SPLITS=['train', 'test', 'valid']\n",
        "SENTS=\"review\"\n",
        "\n",
        "for split in SPLITS:\n",
        "    with open('data/cls.books/'+split+'.'+SENTS, 'r') as f:\n",
        "        reviews = f.readlines()\n",
        "        reviews = # tokenize data\n",
        "        \n",
        "        #It should look something like that\n",
        "        #▁An ci enne ▁VS ▁Nouvelle ▁version ▁plus\n",
        "        print(reviews[0]) \n",
        "    with open('data/cls.books/'+split+'.spm.'+SENTS, 'w') as f:\n",
        "        for review in reviews:\n",
        "          f.write(review+'\\n')\n"
      ],
      "metadata": {
        "id": "D-hOlotmOW7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <b>Binarizing the finetuning dataset</b>\n",
        "\n",
        "In this section, you have to binarize the CLS_Books dataset using the <b>fairseq/fairseq_cli/preprocess.py</b> script:\n",
        "\n",
        "1- Binarize the tokenized reviews and put the output in <b>data/cls-books-bin/input0</b>. Note: Our pretrained model's embedding matrix contains only the embedding of the vocab listed in the dictionary <b>dict.txt</b>\n",
        "\n",
        "2- Binarize the labels (train.label, valid.label and test.label files) and put the output in <b>data/cls-books-bin/label</b>.\n",
        "\n",
        "Use `!python libs/fairseq/fairseq_cli/preprocess.py --help` to get details about the arguments and visit the fairseq github repository for further help."
      ],
      "metadata": {
        "id": "iGNK19XuKBk0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!(python libs/fairseq/fairseq_cli/preprocess.py \\\n",
        "              --only-source \\\n",
        "\n",
        "              --workers 8)#fill me - binarize the tokenized reviews\n",
        "\n",
        "!(python libs/fairseq/fairseq_cli/preprocess.py \\\n",
        "              --only-source \\\n",
        "              \n",
        "              --workers 8)#fill me - binarize the labels"
      ],
      "metadata": {
        "id": "jIF1wvWoFp4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <b>Finetuning $RoBERTa_{small}^{fr}$</b>\n",
        "\n",
        "In this section you will use <b>fairseq/fairseq_cli/train.py</b> python script to finetune the pretrained model on the CLS_Books dataset (binarized data) for three different seeds: 0, 1 and 2. \n",
        "\n",
        "Make sure to use the following hyper-parameters: $\\textit{batch size}=8, \\textit{max number of epochs}: 5, \\textit{optimizer}: Adam, \\textit{max learning rate}: 1e-05,  \\textit{warm up ratio}: 0.06, \\textit{learning rate scheduler}: linear$"
      ],
      "metadata": {
        "id": "2SSjBcQJnuSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_SET='books'\n",
        "TASK= # fill me, sentence prediction task on fairseq\n",
        "MODEL='RoBERTa_small_fr'\n",
        "DATA_PATH= # fill me \n",
        "MODEL_PATH= # fill me\n",
        "MAX_EPOCH= # fill me \n",
        "MAX_SENTENCES= # fill me, batch size\n",
        "MAX_UPDATE= # fill me, n_epochs * n_train_examples / total batch size \n",
        "LR= # fill me\n",
        "VALID_SUBSET='valid,test' # for simplicity we will validate on both valid and test set, and then pick the value of test set corresponding the best validation score. \n",
        "METRIC = # fill me, use the accuracy metric\n",
        "NUM_CLASSES=#fill me, number of classes\n",
        "SEEDS=3\n",
        "CUDA_VISIBLE_DEVICES=0\n",
        "WARMUP = # fill me, warmup ratio=6% of the whole training"
      ],
      "metadata": {
        "id": "JV2112YPJEDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for SEED in range(SEEDS):\n",
        "  TENSORBOARD_LOGS= 'tensorboard_logs/'+TASK+'/'+DATA_SET+'/'+MODEL+'_ms'+str(MAX_SENTENCES)+'_mu'+str(MAX_UPDATE)+'_lr'+str(LR)+'_me'+str(MAX_EPOCH)+'/'+str(SEED)\n",
        "  SAVE_DIR= 'checkpoints/'+TASK+'/'+DATA_SET+'/'+MODEL+'_ms'+str(MAX_SENTENCES)+'_mu'+str(MAX_UPDATE)+'_lr'+str(LR)+'_me'+str(MAX_EPOCH)+'/'+str(SEED)\n",
        "  !(python libs/fairseq/fairseq_cli/train.py $DATA_PATH \\\n",
        "                --restore-file $MODEL_PATH \\\n",
        "                --batch-size $MAX_SENTENCES \\\n",
        "                --task $TASK \\\n",
        "                --update-freq 1 \\\n",
        "                --seed $SEED \\\n",
        "                --reset-optimizer --reset-dataloader --reset-meters \\\n",
        "                --init-token 0 \\\n",
        "                --separator-token 2 \\\n",
        "                --arch roberta_small \\\n",
        "                --criterion sentence_prediction \\\n",
        "                --num-classes $NUM_CLASSES \\\n",
        "                --weight-decay 0.01 \\\n",
        "                --optimizer adam --adam-betas \"(0.9, 0.98)\" --adam-eps 1e-08 \\\n",
        "                --maximize-best-checkpoint-metric \\\n",
        "                --best-checkpoint-metric $METRIC \\\n",
        "                --save-dir $SAVE_DIR \\\n",
        "                --lr-scheduler polynomial_decay \\\n",
        "                --lr $LR \\\n",
        "                --max-update $MAX_UPDATE \\\n",
        "                --total-num-update $MAX_UPDATE \\\n",
        "                --no-epoch-checkpoints \\\n",
        "                --no-last-checkpoints \\\n",
        "                --tensorboard-logdir $TENSORBOARD_LOGS \\\n",
        "                --log-interval 5 \\\n",
        "                --warmup-updates $WARMUP \\\n",
        "                --max-epoch $MAX_EPOCH \\\n",
        "                --keep-best-checkpoints 1 \\\n",
        "                --max-positions 256 \\\n",
        "                --valid-subset $VALID_SUBSET \\\n",
        "                --shorten-method 'truncate' \\\n",
        "                --no-save \\\n",
        "                --distributed-world-size 1)\n"
      ],
      "metadata": {
        "id": "6Mdznms-EYyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <b>Random $RoBERTa_{small}^{fr}$ model training:</b>\n",
        "\n",
        "In this section you have to finetune a random checkpinf of the model $RoBERTa_{small}^{fr}$ using the same setting as before (<b>Hint:</b> an unexisted model path will not give you an error) "
      ],
      "metadata": {
        "id": "wi1U19Uunnse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_SET='books'\n",
        "TASK= # fill me, sentence prediction task on fairseq\n",
        "MODEL='RoBERTa_small_fr_random'\n",
        "DATA_PATH= # fill me \n",
        "MODEL_PATH= # fill me\n",
        "MAX_EPOCH= # fill me \n",
        "MAX_SENTENCES= # fill me, batch size\n",
        "MAX_UPDATE= # fill me, n_epochs * n_train_examples / total batch size \n",
        "LR= # fill me\n",
        "VALID_SUBSET='valid,test' # for simplicity we will validate on both valid and test set, and then pick the value of test set corresponding the best validation score. \n",
        "METRIC = # fill me, use the accuracy metric\n",
        "NUM_CLASSES=#fill me, number of classes\n",
        "SEEDS=3\n",
        "CUDA_VISIBLE_DEVICES=0\n",
        "WARMUP = # fill me, warmup ratio=6% of the whole training"
      ],
      "metadata": {
        "id": "lSLWP6VUhUlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for SEED in range(SEEDS):\n",
        "  TENSORBOARD_LOGS= 'tensorboard_logs/'+TASK+'/'+DATA_SET+'/'+MODEL+'_ms'+str(MAX_SENTENCES)+'_mu'+str(MAX_UPDATE)+'_lr'+str(LR)+'_me'+str(MAX_EPOCH)+'/'+str(SEED)\n",
        "  SAVE_DIR= 'checkpoints/'+TASK+'/'+DATA_SET+'/'+MODEL+'_ms'+str(MAX_SENTENCES)+'_mu'+str(MAX_UPDATE)+'_lr'+str(LR)+'_me'+str(MAX_EPOCH)+'/'+str(SEED)\n",
        "  !(python libs/fairseq/fairseq_cli/train.py $DATA_PATH \\\n",
        "                --restore-file $MODEL_PATH \\\n",
        "                --batch-size $MAX_SENTENCES \\\n",
        "                --task $TASK \\\n",
        "                --update-freq 1 \\\n",
        "                --seed $SEED \\\n",
        "                --reset-optimizer --reset-dataloader --reset-meters \\\n",
        "                --init-token 0 \\\n",
        "                --separator-token 2 \\\n",
        "                --arch roberta_small \\\n",
        "                --criterion sentence_prediction \\\n",
        "                --num-classes $NUM_CLASSES \\\n",
        "                --weight-decay 0.01 \\\n",
        "                --optimizer adam --adam-betas \"(0.9, 0.98)\" --adam-eps 1e-08 \\\n",
        "                --maximize-best-checkpoint-metric \\\n",
        "                --best-checkpoint-metric $METRIC \\\n",
        "                --save-dir $SAVE_DIR \\\n",
        "                --lr-scheduler polynomial_decay \\\n",
        "                --lr $LR \\\n",
        "                --max-update $MAX_UPDATE \\\n",
        "                --total-num-update $MAX_UPDATE \\\n",
        "                --no-epoch-checkpoints \\\n",
        "                --no-last-checkpoints \\\n",
        "                --tensorboard-logdir $TENSORBOARD_LOGS \\\n",
        "                --log-interval 5 \\\n",
        "                --warmup-updates $WARMUP \\\n",
        "                --max-epoch $MAX_EPOCH \\\n",
        "                --keep-best-checkpoints 1 \\\n",
        "                --max-positions 256 \\\n",
        "                --valid-subset $VALID_SUBSET \\\n",
        "                --shorten-method 'truncate' \\\n",
        "                --no-save \\\n",
        "                --distributed-world-size 1)"
      ],
      "metadata": {
        "id": "qtsCysc4hb42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <b>Tensorboard Visualisation </B>\n",
        "\n",
        "In the this we will use tensorboard to visualize the training, validation and test accuracies. <b>Include and analyse in you report a screenshot of the test accuracy of the six models</b>."
      ],
      "metadata": {
        "id": "eHACXaPSLwu4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir tensorboard_logs"
      ],
      "metadata": {
        "id": "pwVvJNExS2dl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <b>Part 2: HuggingFace's Transfromers</b>\n",
        "\n",
        "In this part of the lab, we will finetune a HuggingFace checkpoint of our $RoBERTa_{small}^{fr}$ on the CLS_Books dataset. Like in the first part we will start by downloading the HuggingFace checkpoint and <b>preparing a json format of the CLS_Books dataset</b> (Which is suitable for HuggingFace's checkpoints finetuning). Again, if you are using you personal computer, do not run the following cell and use its content to download the files on you computer, since - depending on you operating system - running this cell will produce errors. "
      ],
      "metadata": {
        "id": "PAR_P343MCKC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd models\n",
        "!wget -c \"https://onedrive.live.com/download?cid=AE69638675180117&resid=AE69638675180117%21267607&authkey=APJub1wVzVLAoR8\" -O \"model_huggingface.zip\"\n",
        "!unzip model_huggingface.zip\n",
        "!rm model_huggingface.zip\n",
        "!rm -rf __MACOSX/\n",
        "\n",
        "%cd ../data\n",
        "!mkdir cls.books-json\n",
        "\n",
        "%cd .."
      ],
      "metadata": {
        "id": "v2ni-Bbql-CX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <b>Converting the CLS_Books dataset to json line files</b>\n",
        "\n",
        "Unlike Fairseq, you do not need to perform tokenization and binarization in Hugging Face transformer library. However, in order to use the implemented script in the transformers library, you need to convert your data to json line files (for each split: train, valid and test)\n",
        "\n",
        "for instance, each line inside you file will consist of one and one sample only, contaning the review (accessed by the key <i>sentence1</i> and its label, accessed by the key <i>label</i>. Below you can find an example from <i>valid.json</i> file.\n",
        "\n",
        "Note that these instructions are not valid for all kind of tasks. For other types of tasks (supported in Hugging face) you have to refer to their github for more details.<br>\n",
        "\n",
        "---------------------------------------------------------------------\n",
        "<i>\n",
        "{\"sentence1\":\"Seul ouvrage fran\\u00e7ais sur le th\\u00e8me Produits Structur\\u00e9s \\/ fonds \\u00e0 formule, il permet de fa\\u00e7on p\\u00e9dagogique d'appr\\u00e9hender parfaitement les m\\u00e9canismes financiers utilis\\u00e9s. Une r\\u00e9f\\u00e9rence pour ceux qui veulent comprendre les technicit\\u00e9s de base et les raisons de l'engouement des investisseurs sur ces actifs \\u00e0 hauteur de plusieurs milliards d'euros.\",\"label\":\"1\"}<br>\n",
        "{\"sentence1\":\"Livre tr\\u00e8s int\\u00e9ressant !  mais si comme moi vous cherchez des \\\"infos\\\" sur les techniques de sorties et autres \\\"modes d'emploi\\\", afin de vivre par vous m\\u00eame ce genre d'exp\\u00e9rience, c'est pas le bon livre.  \\u00e7a ne lui enl\\u00e8ve d'ailleurd rien \\u00e0 son int\\u00earet.\",\"label\":\"0\"}\n",
        "</i>\n",
        "\n",
        "---------------------------------------------------------------------\n",
        "\n"
      ],
      "metadata": {
        "id": "c3M090L45oPn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "SPLITS=['train', 'test', 'valid']\n",
        "\n",
        "for split in SPLITS:\n",
        "    with open('data/cls.books/'+split+'.review', 'r') as f:\n",
        "        reviews = f.readlines()\n",
        "    with open('data/cls.books/'+split+'.label', 'r') as f:\n",
        "        labels = f.readlines()\n",
        "    with open('data/cls.books-json/'+split+'.json', 'w') as f:   \n",
        "        #fill the gap here to create train.json, valid.json and test.json\n"
      ],
      "metadata": {
        "id": "HZZFHEHFyv5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <b>Finetuning $RoBERTa_{small}^{fr}$ using the Transformers Library</b>\n",
        "\n",
        "In order to finrtune the model using HuggingFace, you to use the <b>run_glue.py</b> Python script located in the transformers library. For more details, refer to <a href=\"https://github.com/huggingface/transformers/tree/main/examples/pytorch/text-classification\" target=\"_blank\">the Huggingface/transformers repository on Github</a>. Make sure to use the same hyperparameter as in the first part of this lab."
      ],
      "metadata": {
        "id": "ICnN2FvnhTbs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_SET='books'\n",
        "MODEL='RoBERTa_small_fr_huggingface'\n",
        "MAX_SENTENCES= # fill me, batch size.\n",
        "LR=#fill me, learning rate\n",
        "MAX_EPOCH=#fill me\n",
        "NUM_CLASSES=#fill me\n",
        "SEEDS=3\n",
        "CUDA_VISIBLE_DEVICES=0"
      ],
      "metadata": {
        "id": "h-BBIykNjH7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for SEED in range(SEEDS):\n",
        "  SAVE_DIR= 'checkpoints/'+TASK+'/'+DATA_SET+'/'+MODEL+'_ms'+str(MAX_SENTENCES)+'_lr'+str(LR)+'_me'+str(MAX_EPOCH)+'/'+str(SEED)\n",
        "  !(python libs/transformers/examples/pytorch/text-classification/run_glue.py \\\n",
        "    \n",
        "  )#fill me "
      ],
      "metadata": {
        "id": "lV2Zla33hK_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir checkpoints"
      ],
      "metadata": {
        "id": "d2UMHjatpFvm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}